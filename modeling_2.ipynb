{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dN6adyMwl2S"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtyTRglturFs",
    "outputId": "9157fd9e-e2e2-4da2-c402-15e8b11de480"
   },
   "outputs": [],
   "source": [
    "#!pip install skimpy polars plotly pingouin xgboost lightgbm scikit-optimize optuna category_encoders sklego\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from polars import DataFrame\n",
    "from skimpy import skim\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.io as pio\n",
    "import polars.selectors as cs\n",
    "import pingouin as pg\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skopt import BayesSearchCV\n",
    "from polars import DataFrame\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from typing import Optional\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.linear_model._logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from optuna.trial._frozen import FrozenTrial\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    make_scorer,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    fbeta_score,\n",
    "    roc_auc_score,\n",
    "    make_scorer,\n",
    "    matthews_corrcoef,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble._forest import ExtraTreesClassifier\n",
    "\n",
    "from optuna import Study\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from optuna import Trial,create_study\n",
    "\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from optuna import create_study\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.samplers import RandomSampler\n",
    "import warnings\n",
    "from typing import Optional\n",
    "from pandas import DataFrame\n",
    "from optuna import Trial\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pio.templates.default = \"plotly_dark\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xyoCfFXHuwLb"
   },
   "outputs": [],
   "source": [
    "def calculate_partial_correlation(df, feature1, feature2, control):\n",
    "    return pg.partial_corr(\n",
    "        data=df.to_pandas(), x=feature1, y=feature2, covar=control\n",
    "    )  # ['r'].values[0]\n",
    "\n",
    "\n",
    "def create_encoder_mapping(df, feature) -> dict[str, int]:\n",
    "    \"\"\"Creates dictionary for mapping to encode categorical features\n",
    "\n",
    "    Args:\n",
    "        df (polars dataframe): dataframe of features\n",
    "        feature (string): name of feature of interest\n",
    "\n",
    "    Returns:\n",
    "        encoding_key: dictionary of feature values and numbers for encoding\n",
    "    \"\"\"\n",
    "    df: DataFrame = (\n",
    "        df.group_by(feature)\n",
    "        .agg(pl.len().alias(\"values\"))\n",
    "        .sort(\"values\", descending=True)\n",
    "    )\n",
    "\n",
    "    options: List = df[feature].to_list()\n",
    "\n",
    "    numbers_to_encode = list(range(0, len(options)))\n",
    "    encoding_key = {options[i]: numbers_to_encode[i] for i in range(len(options))}\n",
    "\n",
    "    if df[feature].str.contains(\"Yes\").to_list()[0] == True:\n",
    "        encoding_key: dict[str, int] = {\"Yes\": 1, \"No\": 0}\n",
    "\n",
    "    return encoding_key\n",
    "\n",
    "\n",
    "def encode_feature(df, feature, encoding_key) -> DataFrame:\n",
    "    \"\"\"Encode features using supplied encoding key\n",
    "\n",
    "    Args:\n",
    "        df (polars): Dataframe to be modified\n",
    "        feature (string): feature to be encoded\n",
    "        encoding_key (dict): dictionary of values and numerical codes\n",
    "\n",
    "    Returns:\n",
    "        df: input dataframe with feature replaced by numerical values\n",
    "    \"\"\"\n",
    "    df: DataFrame = df.with_columns(\n",
    "        df.select(pl.col(feature).replace(encoding_key)).cast({feature: pl.Int64})\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def retrieve_csv_columns(csv):\n",
    "    df = pl.read_csv(csv).head(1)\n",
    "    columns = set(lower_column_names(df).columns)\n",
    "    return columns\n",
    "\n",
    "\n",
    "def find_common_key(table1, table2) -> str:\n",
    "    \"\"\"For two names of csv files given as strings, return the common key column between them\"\"\"\n",
    "    sk_id_set = set(\n",
    "        [\n",
    "            \"bureau.csv\",\n",
    "            \"previous_application.csv\",\n",
    "            \"credit_card_balance.csv\",\n",
    "            \"installments_payments.csv\",\n",
    "            \"pos_cash_balance.csv\",\n",
    "            \"application_test.csv\",\n",
    "            \"application_train.csv\",\n",
    "        ]\n",
    "    )\n",
    "    sk_id_bureau_set = set([\"bureau.csv\", \"bureau_balance.csv\"])\n",
    "    sk_id_prev_set = set(\n",
    "        [\n",
    "            \"pos_cash_balance.csv\",\n",
    "            \"installments_payments.csv\",\n",
    "            \"credit_card_balance.csv\",\n",
    "            \"previous_application.csv\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if (table1 in sk_id_set) & (table2 in sk_id_set):\n",
    "        return \"sk_id_curr\"\n",
    "    elif (table1 in sk_id_bureau_set) & (table2 in sk_id_bureau_set):\n",
    "        return \"sk_id_bureau\"\n",
    "    elif (table1 in sk_id_prev_set) & (table2 in sk_id_set):\n",
    "        return \"sk_id_prev\"\n",
    "    else:\n",
    "        print(\"no common key found for these tables\")\n",
    "\n",
    "\n",
    "def tables_with_feature(description_df, feature):\n",
    "    tables = set(\n",
    "        description_df.filter(pl.col(\"row\") == feature)\n",
    "        .select(\"table\")\n",
    "        .unique()\n",
    "        .to_series()\n",
    "    )\n",
    "\n",
    "    if len(tables) == 0:\n",
    "        print(\"no results found.\")\n",
    "    else:\n",
    "        return tables\n",
    "\n",
    "\n",
    "def calculate_null_count(train, table, feature, mode=\"null_count\"):\n",
    "    #nulls = []\n",
    "    if table == \"application_{train|test}.csv\":\n",
    "        if mode == \"null_count\":\n",
    "            return train[feature].null_count()\n",
    "        elif mode == \"series\":\n",
    "            return train[feature]\n",
    "        # nulls.append(train[feature].null_count())\n",
    "    else:\n",
    "        alternate_df = create_formatted_df(table)\n",
    "        key = find_common_key(\"application_train.csv\", table)\n",
    "        temp_df = train.join(alternate_df, on=key, how=\"inner\")\n",
    "    if mode == \"null_count\":\n",
    "        return temp_df[feature].null_count()\n",
    "    elif mode == \"series\":\n",
    "        return temp_df[feature].to_series()\n",
    "\n",
    "\n",
    "def null_count_comparison(train, description, feature):\n",
    "    tables = tables_with_feature(description, feature)\n",
    "\n",
    "    nulls = []\n",
    "    for table in tables:\n",
    "        null_count = calculate_null_count(train, table, feature, mode=\"null_count\")\n",
    "        nulls.append(null_count)\n",
    "    df = pl.DataFrame(\n",
    "        data={\"table\": list(tables), \"feature\": feature, \"null_count\": nulls},\n",
    "        schema={\"table\": pl.String, \"feature\": pl.String, \"null_count\": pl.Int64},\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_feature(train, null_df, feature) -> DataFrame:\n",
    "    \"\"\"Replace feature with fewer null values in train, else return training set unchanged\"\"\"\n",
    "    null_min = null_df[\"null_count\"].min()\n",
    "    table = null_df.filter(pl.col(\"null_count\") == null_min).select(\"table\").item()\n",
    "    if table == \"application_{train|test}.csv\":\n",
    "        return train\n",
    "    else:\n",
    "        key = find_common_key(\"application_train.csv\", table)\n",
    "        alternate_df = create_formatted_df(table)[[key, feature]]\n",
    "        alternate_feature = train.join(alternate_df, on=key, how=\"inner\")[\n",
    "            feature\n",
    "        ].to_series()\n",
    "        train = train.with_columns(alternate_feature.alias(feature))\n",
    "        return train\n",
    "\n",
    "\n",
    "def hypothesis_test_multiple_proportions(train_df, feature):\n",
    "    \"\"\"Conducts hypothesis test comparing target proportion and feature proportion\"\"\"\n",
    "\n",
    "    # Determine the number of values in feature\n",
    "    feature_default_df = pd.crosstab(\n",
    "        train_df[feature].to_pandas(),\n",
    "        train_df[\"target\"].to_pandas(),\n",
    "        rownames=[feature],\n",
    "        colnames=[\"target\"],\n",
    "    )\n",
    "    feature_default_df[\"default_proportion\"] = feature_default_df.iloc[\n",
    "        :, 1\n",
    "    ] / feature_default_df.sum(axis=1)\n",
    "    feature_default_df[\"total\"] = feature_default_df.iloc[:, :-1].sum(axis=1)\n",
    "\n",
    "    # pooled sample proportion\n",
    "    p1_default_prop = feature_default_df.default_proportion.iloc[0]\n",
    "    p2_default_prop = feature_default_df.default_proportion.iloc[1]\n",
    "    p1_population = feature_default_df.total.iloc[0]\n",
    "    p2_population = feature_default_df.total.iloc[1]\n",
    "\n",
    "    p = (p1_default_prop * p1_population + p2_default_prop * p2_population) / (\n",
    "        p1_population + p2_population\n",
    "    )\n",
    "\n",
    "    # standard error\n",
    "    se = np.sqrt((p * (1 - p)) * ((1 / p1_population) + (1 / p2_population)))\n",
    "\n",
    "    # test statistic\n",
    "    z = (p1_default_prop - p2_default_prop) / se\n",
    "\n",
    "    if np.abs(z) < 1.64485:\n",
    "        print(\n",
    "            f\"Fail to reject the null hypothesis. We can assume the default percentage to be the same across {feature}.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"z = {z:.3f}. Reject null hypothesis. The proportion of credit defaults across values of {feature} is not equal.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def np_to_df(array, feature_list, designation=\"pd\"):\n",
    "    if designation == \"pd\":\n",
    "        return pd.DataFrame(array, columns=feature_list)\n",
    "    if designation == \"pl\":\n",
    "        df = pl.DataFrame(array)\n",
    "        df.columns = feature_list\n",
    "        return df\n",
    "\n",
    "\n",
    "def conduct_grid_search_tuning(\n",
    "    model, grid, x_train, y_train, refit, scoring=make_scorer(fbeta_score, beta=2), cv=5\n",
    "):\n",
    "    \"\"\"Conducts gridsearch for specified model and hyperparameter settings\n",
    "\n",
    "    Args:\n",
    "        model (string): string specifying model to test, must be 'knn', 'logistic_regression','decision_tree', or 'random_forest'\n",
    "        grid (dictionary): grid of lists specifying options for hyperparameters to tune\n",
    "        xy (list): x and y for model fitting, should be in [x_train,y_train] format\n",
    "        scoring(string/callable): string defines scoring method to be used within grid search\n",
    "    \"\"\"\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model, grid, cv=cv, scoring=scoring, refit=refit, n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_params  # , grid_search\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def skopt_bayesian_search(classifier, x_train, y_train, params):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "    search = BayesSearchCV(estimator=classifier, search_spaces=params, n_jobs=-1, cv=cv)\n",
    "    search.fit(x_train, y_train)\n",
    "    return search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HDD8WUY6urFs"
   },
   "outputs": [],
   "source": [
    "from loan_functions import (\n",
    "    create_formatted_df,\n",
    "    make_subplot,\n",
    "    lower_column_names,\n",
    "    lower_column_values,\n",
    "    column_description,\n",
    "    plot_histogram,\n",
    "    column_comparison,\n",
    "    int_range,\n",
    "    clear,\n",
    "    calculate_value_counts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCapjrYUurFs"
   },
   "source": [
    "We'll read in the csv datasets one by one to save on memory, clearing them each time. Let's start with the training set, followed by our other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading in the training set and looking at balance. I'll keep the EDA of this notebook focused on the training set to have a more focused analysis and discussion of modeling and model performance, but a more detailed exploration of the supporting datasets can be found in the [notebook] found in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 307511 rows and 122 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 122)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sk_id_curr</th><th>target</th><th>name_contract_type</th><th>code_gender</th><th>flag_own_car</th><th>flag_own_realty</th><th>cnt_children</th><th>amt_income_total</th><th>amt_credit</th><th>amt_annuity</th><th>amt_goods_price</th><th>name_type_suite</th><th>name_income_type</th><th>name_education_type</th><th>name_family_status</th><th>name_housing_type</th><th>region_population_relative</th><th>days_birth</th><th>days_employed</th><th>days_registration</th><th>days_id_publish</th><th>own_car_age</th><th>flag_mobil</th><th>flag_emp_phone</th><th>flag_work_phone</th><th>flag_cont_mobile</th><th>flag_phone</th><th>flag_email</th><th>occupation_type</th><th>cnt_fam_members</th><th>region_rating_client</th><th>region_rating_client_w_city</th><th>weekday_appr_process_start</th><th>hour_appr_process_start</th><th>reg_region_not_live_region</th><th>reg_region_not_work_region</th><th>live_region_not_work_region</th><th>&hellip;</th><th>nonlivingarea_medi</th><th>fondkapremont_mode</th><th>housetype_mode</th><th>totalarea_mode</th><th>wallsmaterial_mode</th><th>emergencystate_mode</th><th>obs_30_cnt_social_circle</th><th>def_30_cnt_social_circle</th><th>obs_60_cnt_social_circle</th><th>def_60_cnt_social_circle</th><th>days_last_phone_change</th><th>flag_document_2</th><th>flag_document_3</th><th>flag_document_4</th><th>flag_document_5</th><th>flag_document_6</th><th>flag_document_7</th><th>flag_document_8</th><th>flag_document_9</th><th>flag_document_10</th><th>flag_document_11</th><th>flag_document_12</th><th>flag_document_13</th><th>flag_document_14</th><th>flag_document_15</th><th>flag_document_16</th><th>flag_document_17</th><th>flag_document_18</th><th>flag_document_19</th><th>flag_document_20</th><th>flag_document_21</th><th>amt_req_credit_bureau_hour</th><th>amt_req_credit_bureau_day</th><th>amt_req_credit_bureau_week</th><th>amt_req_credit_bureau_mon</th><th>amt_req_credit_bureau_qrt</th><th>amt_req_credit_bureau_year</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>&hellip;</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>364758</td><td>0</td><td>&quot;revolving loans&quot;</td><td>&quot;m&quot;</td><td>&quot;n&quot;</td><td>&quot;y&quot;</td><td>0</td><td>270000.0</td><td>337500.0</td><td>16875.0</td><td>337500.0</td><td>&quot;unaccompanied&quot;</td><td>&quot;commercial associate&quot;</td><td>&quot;secondary / secondary special&quot;</td><td>&quot;married&quot;</td><td>&quot;house / apartment&quot;</td><td>0.018801</td><td>-17556</td><td>-1749</td><td>-6464.0</td><td>-1092</td><td>null</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>&quot;laborers&quot;</td><td>2.0</td><td>2</td><td>2</td><td>&quot;friday&quot;</td><td>9</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0.0</td><td>&quot;reg oper spec account&quot;</td><td>&quot;block of flats&quot;</td><td>0.0531</td><td>&quot;panel&quot;</td><td>&quot;no&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-1799.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>230922</td><td>0</td><td>&quot;cash loans&quot;</td><td>&quot;f&quot;</td><td>&quot;y&quot;</td><td>&quot;n&quot;</td><td>0</td><td>270000.0</td><td>900000.0</td><td>26446.5</td><td>900000.0</td><td>&quot;unaccompanied&quot;</td><td>&quot;working&quot;</td><td>&quot;higher education&quot;</td><td>&quot;married&quot;</td><td>&quot;house / apartment&quot;</td><td>0.014464</td><td>-12092</td><td>-1178</td><td>-2236.0</td><td>-3768</td><td>6.0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>&quot;hr staff&quot;</td><td>2.0</td><td>2</td><td>2</td><td>&quot;wednesday&quot;</td><td>13</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>-2162.0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>4.0</td></tr><tr><td>384117</td><td>0</td><td>&quot;cash loans&quot;</td><td>&quot;f&quot;</td><td>&quot;n&quot;</td><td>&quot;n&quot;</td><td>0</td><td>270000.0</td><td>219042.0</td><td>21793.5</td><td>193500.0</td><td>&quot;unaccompanied&quot;</td><td>&quot;working&quot;</td><td>&quot;higher education&quot;</td><td>&quot;married&quot;</td><td>&quot;house / apartment&quot;</td><td>0.04622</td><td>-17988</td><td>-2547</td><td>-8610.0</td><td>-1543</td><td>null</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>&quot;private service staff&quot;</td><td>2.0</td><td>1</td><td>1</td><td>&quot;friday&quot;</td><td>12</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0.0</td><td>&quot;reg oper account&quot;</td><td>&quot;block of flats&quot;</td><td>0.061</td><td>&quot;panel&quot;</td><td>&quot;no&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-11.0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>198787</td><td>0</td><td>&quot;cash loans&quot;</td><td>&quot;f&quot;</td><td>&quot;n&quot;</td><td>&quot;y&quot;</td><td>0</td><td>76500.0</td><td>332842.5</td><td>12676.5</td><td>234000.0</td><td>&quot;unaccompanied&quot;</td><td>&quot;working&quot;</td><td>&quot;secondary / secondary special&quot;</td><td>&quot;widow&quot;</td><td>&quot;house / apartment&quot;</td><td>0.005313</td><td>-19458</td><td>-1796</td><td>-1662.0</td><td>-2982</td><td>null</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>&quot;core staff&quot;</td><td>1.0</td><td>2</td><td>2</td><td>&quot;monday&quot;</td><td>18</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0.0172</td><td>null</td><td>&quot;block of flats&quot;</td><td>0.1316</td><td>&quot;stone, brick&quot;</td><td>&quot;no&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-2510.0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>122372</td><td>0</td><td>&quot;revolving loans&quot;</td><td>&quot;m&quot;</td><td>&quot;y&quot;</td><td>&quot;y&quot;</td><td>1</td><td>135000.0</td><td>270000.0</td><td>13500.0</td><td>270000.0</td><td>&quot;unaccompanied&quot;</td><td>&quot;working&quot;</td><td>&quot;secondary / secondary special&quot;</td><td>&quot;married&quot;</td><td>&quot;house / apartment&quot;</td><td>0.020713</td><td>-15925</td><td>-1514</td><td>-8183.0</td><td>-4785</td><td>6.0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>&quot;managers&quot;</td><td>3.0</td><td>3</td><td>2</td><td>&quot;tuesday&quot;</td><td>12</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0.0509</td><td>&quot;reg oper account&quot;</td><td>&quot;block of flats&quot;</td><td>0.0575</td><td>&quot;stone, brick&quot;</td><td>&quot;no&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 122)\n",
       "┌────────────┬────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ sk_id_curr ┆ target ┆ name_contr ┆ code_gend ┆ … ┆ amt_req_c ┆ amt_req_c ┆ amt_req_c ┆ amt_req_c │\n",
       "│ ---        ┆ ---    ┆ act_type   ┆ er        ┆   ┆ redit_bur ┆ redit_bur ┆ redit_bur ┆ redit_bur │\n",
       "│ i64        ┆ i64    ┆ ---        ┆ ---       ┆   ┆ eau_week  ┆ eau_mon   ┆ eau_qrt   ┆ eau_year  │\n",
       "│            ┆        ┆ str        ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆        ┆            ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 364758     ┆ 0      ┆ revolving  ┆ m         ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│            ┆        ┆ loans      ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 230922     ┆ 0      ┆ cash loans ┆ f         ┆ … ┆ 0.0       ┆ 0.0       ┆ 1.0       ┆ 4.0       │\n",
       "│ 384117     ┆ 0      ┆ cash loans ┆ f         ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 198787     ┆ 0      ┆ cash loans ┆ f         ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│ 122372     ┆ 0      ┆ revolving  ┆ m         ┆ … ┆ 0.0       ┆ 0.0       ┆ 1.0       ┆ 0.0       │\n",
       "│            ┆        ┆ loans      ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train = create_formatted_df(\"application_train.csv\")\n",
    "\n",
    "print(\n",
    "    f\"Training set has {application_train.shape[0]} rows and {application_train.shape[1]} columns.\"\n",
    ")\n",
    "\n",
    "application_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at balance of the target variable since that is our modeling variable of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           "91.9%"
          ],
          [
           "8.1%"
          ]
         ],
         "hovertemplate": "target=%{marker.color}<br>count=%{y}<br>percentages=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0,
           1
          ],
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          "91.9%",
          "8.1%"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          0,
          1
         ],
         "xaxis": "x",
         "y": [
          282686,
          24825
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "bargap": 0.2,
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "target"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(210, 251, 212)"
          ],
          [
           0.16666666666666666,
           "rgb(165, 219, 194)"
          ],
          [
           0.3333333333333333,
           "rgb(123, 188, 176)"
          ],
          [
           0.5,
           "rgb(85, 156, 158)"
          ],
          [
           0.6666666666666666,
           "rgb(58, 124, 137)"
          ],
          [
           0.8333333333333334,
           "rgb(35, 93, 114)"
          ],
          [
           1,
           "rgb(18, 63, 90)"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Target Variable Distribution"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "target"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(application_train, \"target\", title=\"Target Variable Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>table</th><th>feature</th><th>null_count</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;previous_application.csv&quot;</td><td>&quot;amt_annuity&quot;</td><td>93</td></tr><tr><td>&quot;application_{train|test}.csv&quot;</td><td>&quot;amt_annuity&quot;</td><td>12</td></tr><tr><td>&quot;bureau.csv&quot;</td><td>&quot;amt_annuity&quot;</td><td>42</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌──────────────────────────────┬─────────────┬────────────┐\n",
       "│ table                        ┆ feature     ┆ null_count │\n",
       "│ ---                          ┆ ---         ┆ ---        │\n",
       "│ str                          ┆ str         ┆ i64        │\n",
       "╞══════════════════════════════╪═════════════╪════════════╡\n",
       "│ previous_application.csv     ┆ amt_annuity ┆ 93         │\n",
       "│ application_{train|test}.csv ┆ amt_annuity ┆ 12         │\n",
       "│ bureau.csv                   ┆ amt_annuity ┆ 42         │\n",
       "└──────────────────────────────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = pl.read_csv(\"HomeCredit_columns_description.csv\", encoding=\"latin1\")\n",
    "description = lower_column_names(description)\n",
    "description = lower_column_values(description)\n",
    "\n",
    "# Delete training spaces for some entries in the row column\n",
    "description = description.with_columns(\n",
    "    pl.col(\"row\").map_elements(lambda x: x.split(\" \")[0], return_dtype=pl.String)\n",
    ")\n",
    "\n",
    "null_df = null_count_comparison(application_train, description, \"amt_annuity\")\n",
    "null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "percentage=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "texttemplate": "%{value}",
         "type": "histogram",
         "x": [
          0.6987229585647583,
          0.6987229585647583,
          0.6987229585647583,
          0.6943296194076538,
          0.6943296194076538,
          0.6943296194076538,
          0.6838617324829102,
          0.6835495233535767,
          0.6835495233535767,
          0.6835495233535767,
          0.6784862875938416,
          0.6784862875938416,
          0.6784862875938416,
          0.6649778485298157,
          0.6649778485298157,
          0.6649778485298157,
          0.6599081158638,
          0.5937674045562744,
          0.5937674045562744,
          0.5937674045562744,
          0.5851595401763916,
          0.5851595401763916,
          0.5851595401763916,
          0.5638107061386108,
          0.5517916679382324,
          0.5517916679382324,
          0.5517916679382324,
          0.5329598188400269,
          0.5329598188400269,
          0.5329598188400269,
          0.5084078311920166,
          0.5074973106384277,
          0.5074973106384277,
          0.5074973106384277,
          0.5034877061843872,
          0.5034877061843872,
          0.5034877061843872,
          0.5019332766532898,
          0.5019332766532898,
          0.5019332766532898,
          0.5017609000205994,
          0.4976082146167755,
          0.4976082146167755,
          0.4976082146167755,
          0.4878101944923401,
          0.4878101944923401,
          0.4878101944923401,
          0.4826851785182953,
          0.4739830493927002,
          0.3134554624557495,
          0.1982530653476715,
          0.1350163072347641,
          0.1350163072347641,
          0.1350163072347641,
          0.1350163072347641,
          0.1350163072347641,
          0.1350163072347641,
          0.004201475530862808,
          0.0033202064223587513,
          0.0033202064223587513,
          0.0033202064223587513,
          0.0033202064223587513,
          0.002146264770999551,
          0.0009040327277034521,
          0.00003902299431501888,
          0.00000650383253741893,
          0.000003251916268709465,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "bargap": 0.2,
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Null value percentages across dataset"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "percentage"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_df = (\n",
    "    application_train.null_count()\n",
    "    .transpose(include_header=True)\n",
    "    .rename(mapping={\"column\": \"feature\", \"column_0\": \"null_count\"})\n",
    "    .sort(by=\"null_count\", descending=True)\n",
    "    .with_columns(\n",
    "        pl.col(\"null_count\")\n",
    "        .map_elements(lambda x: x / len(application_train), return_dtype=pl.Float32)\n",
    "        .alias(\"percentage\")\n",
    "    )\n",
    ")\n",
    "\n",
    "px.histogram(\n",
    "    null_df,\n",
    "    x=\"percentage\",\n",
    "    text_auto=True,\n",
    "    title=\"Null value percentages across dataset\",\n",
    ").update_layout(bargap=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows that we have a pretty wide spread of null value prevalence within this dataset. Thankfully none of these null values are in the target variable, but we will have to make a choice in our analysis of how to treat null values within this dataset since some classifiers are more tolerant of null values than others. LightGBM and XGBoost can handle null values when fitting, but commonly used sklearn classifiers do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look for categorical anomalies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "target=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          -0.0021084690181960766,
          1,
          0.01918713359627062,
          -0.003981865601205793,
          -0.03036928646142988,
          -0.012816561515413605,
          -0.039645281169544896,
          -0.037227148542444764,
          0.07823930830982459,
          -0.04493166265773831,
          0.04197486283141728,
          0.05145717260705659,
          0.0376115642751661,
          0.0005343955790422479,
          0.04598221971659226,
          0.028524322363216906,
          0.00037012680234920295,
          -0.023806272330357217,
          -0.0017583834312544816,
          0.009307784396531512,
          0.058899014945713445,
          0.06089266756482329,
          -0.02416583143009371,
          0.005575944520908343,
          0.006941907545371869,
          0.002819479184159081,
          0.044395374805700945,
          0.05099446436812648,
          0.03251834110149831,
          -0.1553171260639496,
          -0.16047167160520875,
          -0.17891869762837048,
          -0.0294975646334316,
          -0.022745743190148507,
          -0.009727673268680202,
          -0.022149284063388727,
          -0.018549661629760343,
          -0.03419879367526856,
          -0.019172182012738025,
          -0.044003370532402865,
          -0.033613503251899074,
          -0.010884822678806584,
          -0.025030533291064243,
          -0.03299711746761117,
          -0.0031761075207260804,
          -0.013578069781984715,
          -0.02728387066775288,
          -0.01995228392431536,
          -0.009036447354301175,
          -0.02206820383485666,
          -0.016340337311304406,
          -0.03213117100499533,
          -0.017387422304882893,
          -0.04322626321381947,
          -0.03269782531047472,
          -0.010174103567660405,
          -0.023393245570197525,
          -0.030684615765641635,
          -0.001556560845903716,
          -0.01271054374887829,
          -0.029183758876693472,
          -0.022081261373189838,
          -0.009993096559696444,
          -0.022325926477474216,
          -0.018572868907710774,
          -0.033862876768446605,
          -0.019024756327399944,
          -0.04376792104770143,
          -0.033394287191135595,
          -0.011255826639923302,
          -0.02462066360650495,
          -0.03273928440781497,
          -0.0027571486021083394,
          -0.013336719980273935,
          -0.032595546758941996,
          0.0091306657027761,
          0.03224757925304534,
          0.009022143630215059,
          0.031276472126435764,
          0.055218483513459246,
          0.005417144279619328,
          0.044346346851144976,
          -0.0026720821701620937,
          -0.00031577741664638075,
          -0.02860189397306156,
          -0.0015195031600879073,
          -0.00804038446605664,
          -0.004352408580842042,
          -0.0014138915975241474,
          -0.004229349652160023,
          -0.0007557507043578883,
          -0.01158322234141947,
          -0.009463821935576941,
          -0.006535657584094894,
          -0.011614671588293178,
          -0.0033775691474138337,
          -0.007952385099462259,
          -0.001357518324300817,
          0.00021539355797734155,
          0.003708625029306583,
          0.0009304246096946755,
          0.0027044013780418243,
          0.000787711748903683,
          -0.012462419228138606,
          -0.0020219274353457245,
          0.019929858569467208
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "bargap": 0.2,
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correlations with Target Variable"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "target"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Any\n",
    "from numpy import dtype\n",
    "from numpy._typing._array_like import NDArray\n",
    "from pandas import Index\n",
    "from pandas.core.frame import DataFrame\n",
    "from pandas.io.formats.style import Styler\n",
    "\n",
    "\n",
    "corr: DataFrame = (\n",
    "    application_train.select(cs.by_dtype(pl.NUMERIC_DTYPES)).to_pandas().corr()\n",
    ")\n",
    "corr = pd.DataFrame(corr[\"target\"])\n",
    "\n",
    "px.histogram(\n",
    "    corr, \"target\", title=\"Correlations with Target Variable\"\n",
    ").update_layout(bargap=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows the distribution of correlations as a graphical distribution rather than in tabular form because we have so many variables that we're working with. None of our variables are correlated with target, save for target itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there difference in proportions of clients that default when broken down by their region of residence? \n",
    "$H_0$: $p_1$ = $p_2$ = $p_3$<br>\n",
    "$H_1$: $p_1$ $\\neq$ $p_2$ $\\neq$ $p_3$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = -82.387. Reject null hypothesis. The proportion of credit defaults across values of region_rating_client is not equal.\n"
     ]
    }
   ],
   "source": [
    "region_default = pd.crosstab(\n",
    "    application_train[\"region_rating_client\"].to_pandas(),\n",
    "    application_train[\"target\"].to_pandas(),\n",
    "    rownames=[\"region_rating_client\"],\n",
    "    colnames=[\"target\"],\n",
    ")\n",
    "region_default[\"default_proportion\"] = region_default.iloc[:, 1] / region_default.sum(\n",
    "    axis=1\n",
    ")\n",
    "region_default[\"total\"] = region_default.iloc[:, :-1].sum(axis=1)\n",
    "\n",
    "# pooled sample proportion\n",
    "p1_default_prop = region_default.default_proportion.iloc[0]\n",
    "p2_default_prop = region_default.default_proportion.iloc[1]\n",
    "p3_default_prop = region_default.default_proportion.iloc[2]\n",
    "\n",
    "p1_population = region_default.total.iloc[0]\n",
    "p2_population = region_default.total.iloc[1]\n",
    "p3_population = region_default.total.iloc[2]\n",
    "\n",
    "p = (\n",
    "    p1_default_prop * p1_population\n",
    "    + p2_default_prop * p2_population\n",
    "    + p3_default_prop * p3_population\n",
    ") / (p1_population + p2_population + p3_population)\n",
    "\n",
    "# standard error\n",
    "se = np.sqrt(\n",
    "    (p * (1 - p)) * ((1 / p1_population) + (1 / p2_population) + (1 / p2_population))\n",
    ")\n",
    "\n",
    "# test statistic\n",
    "z = (p1_default_prop - p2_default_prop - p3_default_prop) / se\n",
    "\n",
    "if np.abs(z) < 1.64485:\n",
    "    print(\n",
    "        f\"Fail to reject the null hypothesis. We can assume the default percentage to be the same across {'region_rating_client'}.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"z = {z:.3f}. Reject null hypothesis. The proportion of credit defaults across values of {'region_rating_client'} is not equal.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both gender and region are not equal across their values when compared to our target variable, we they are more likely to have a significant relationship with default risk. We should include these variables in our predictor pool. This raises the question of what variables we should use to predict our models, given that we feasibly cannot include all of them. Let's move on to feature selection so we can restrict our feature set to one that is both significant and predictive of the target variable without being so onerous to run calculations on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are younger homeowners are more likely to default on credit payments? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: $\\mu_d$ =  $\\mu_n$<br>\n",
    "$H_1$:  $\\mu_d$ $\\neq$ $\\mu_n$\n",
    "\n",
    "s.t. <br>\n",
    "$\\mu_d$: the average age of clients who default<br>\n",
    "$\\mu_n$: the average age of clients who do not default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "\n",
      "t-statistic: 43.517\n",
      "p-value: 0.000\n",
      "\n",
      "Reject the null hypothesis: There is a significant difference in the average ages \n",
      "of clients who default vs. those who don't.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "age_df: DataFrame = application_train[[\"target\", \"days_birth\"]]\n",
    "age_df = age_df.with_columns((pl.col(\"days_birth\") // -365)).rename(\n",
    "    {\"days_birth\": \"age\"}\n",
    ")\n",
    "\n",
    "age_default = age_df.filter(pl.col(\"target\") == 1)[\"age\"]\n",
    "age_no_default = age_df.filter(pl.col(\"target\") == 0)[\"age\"]\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(age_no_default, age_default)\n",
    "\n",
    "print(\"Two-sample t-test results:\\n\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.3f}\\n\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"Reject the null hypothesis: There is a significant difference in the average ages \\nof clients who default vs. those who don't.\\n\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Fail to reject the null hypothesis: There is no significant difference in the average ages of clients who \\ndefault vs. those who don't.\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_statistics(y_true, y_predict, beta=3.0, title=\"statistics\"):\n",
    "    \"\"\"Uses actual y and predicted y values to return a dataframe of accuracy, precision, recall, and f-beta values as well as false negative and false posititive rates for a given classifier\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy array or data series): dependent variable values from the dataset\n",
    "        y_predict (_type_): dependent variable values arising from model\n",
    "        beta (float, optional): Beta value to determine weighting between precision and recall in the f-beta score.Defaults to beta value set in global scope of this notebook.\n",
    "        title (str, optional): _description_. Defaults to \"statistics\".\n",
    "\n",
    "    Returns:\n",
    "        model_statistics: pandas dataframe of statistics\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()\n",
    "\n",
    "    # calculate statistics from confusion matrix\n",
    "    # accuracy: float = accuracy_score(y_true, y_predict)\n",
    "    roc_auc: float = roc_auc_score(y_true, y_predict)\n",
    "    mcc: float = matthews_corrcoef(y_true, y_predict)\n",
    "    f_beta: float = fbeta_score(y_true, y_predict, beta=beta)\n",
    "\n",
    "    precision: float = precision_score(y_true, y_predict, zero_division=0)\n",
    "    recall: float = recall_score(y_true, y_predict)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true,y_predict)\n",
    "    # false_negative_rate: float = fn / (tn + fp + fn + tp)\n",
    "    # false_positive_rate: float = fp / (tn + fp + fn + tp)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        data={\n",
    "            title: [\n",
    "                roc_auc,\n",
    "                mcc,\n",
    "                f_beta,\n",
    "                precision,\n",
    "                recall,\n",
    "                balanced_accuracy\n",
    "                # accuracy,\n",
    "                # false_negative_rate,\n",
    "                # false_positive_rate,\n",
    "            ]\n",
    "        },\n",
    "        index=[\n",
    "            \"roc_auc\",\n",
    "            \"matthews_correlation\",\n",
    "            \"f_beta\",\n",
    "            \"precision\",\n",
    "            \"recall\",\n",
    "            \"balanced_accuracy\"\n",
    "            # \"accuracy\",\n",
    "            # \"false_negative_rate\",\n",
    "            # \"false_positive_rate\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start creating models, it's important to lay out what our north star assessment criteria are for model assessment, and secondarily how we will choose what a high-performing model is. \n",
    "\n",
    "Given that our business problem is designing predictive classifiers of credit clients that are likely to default on payments, and that our training data is highly imbalanced such that our positive class is the minority class at a ratio of 10:1, we will need to be very precise in our metric selection. \n",
    "\n",
    "Therefore each model that we create will be judged on its ROC-AUC score, F1 score, Matthews Correlation Coefficient, Balanced Accuracy, Precision, and Recall. This sounds like a long list of metrics, so our primary determinants will be the ROC-AUC and MCC since ROC-AUC can be less powerful for highly imbalanced datasets, and MCC gives a pretty comprehensive view of a model's performance across all 4 quadrants of the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svdmqv55uwMC"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined our metrics set and evaluation method, our workflow for the next section is as follows: \n",
    "1. Create pipelines to impute missing values, scale data, and fit to our classifier of choice\n",
    "2. Calculate model statistics for each classifier\n",
    "\n",
    "\n",
    "Let's setup some initial arrays/dataframes, as well as functions we'll need to use in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cQ9821wAuwMD"
   },
   "outputs": [],
   "source": [
    "application_train = create_formatted_df(\"application_train.csv\")\n",
    "\n",
    "x = (\n",
    "    application_train\n",
    "    # .drop(cs.matches(\"flag_document_\"))\n",
    "    .drop([\"sk_id_curr\", \"target\"]).to_pandas()\n",
    ")\n",
    "y = pl.DataFrame(application_train[\"target\"]).to_pandas()\n",
    "\n",
    "# x_columns = x.columns\n",
    "# y_columns = y.columns\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=0, stratify=y\n",
    ")\n",
    "y_train = np.array(y_train).ravel()\n",
    "\n",
    "numerical_columns = [*x.select_dtypes(exclude=[\"object\", \"category\"]).columns]\n",
    "\n",
    "categorical_columns = [*x.select_dtypes(include=[\"object\", \"category\"]).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_rTD-Z3yuwMD"
   },
   "outputs": [],
   "source": [
    "def instantiate_numerical_simple_imputer(\n",
    "    trial: Trial, fill_value: int = -1\n",
    ") -> SimpleImputer:\n",
    "    strategy = trial.suggest_categorical(\n",
    "        \"numerical_strategy\", [\"mean\", \"median\", \"most_frequent\", \"constant\"]\n",
    "    )\n",
    "    return SimpleImputer(strategy=strategy, fill_value=fill_value)\n",
    "\n",
    "\n",
    "def instantiate_categorical_simple_imputer(\n",
    "    trial: Trial, fill_value: str = \"missing\"\n",
    ") -> SimpleImputer:\n",
    "    strategy = trial.suggest_categorical(\n",
    "        \"categorical_strategy\", [\"most_frequent\", \"constant\"]\n",
    "    )\n",
    "    return SimpleImputer(strategy=strategy, fill_value=fill_value)\n",
    "\n",
    "\n",
    "def instantiate_woe_encoder(trial: Trial) -> WOEEncoder:\n",
    "    params = {\n",
    "        \"sigma\": trial.suggest_float(\"sigma\", 0.001, 5),\n",
    "        \"regularization\": trial.suggest_float(\"regularization\", 0, 5),\n",
    "        \"randomized\": trial.suggest_categorical(\"randomized\", [True, False]),\n",
    "    }\n",
    "    return WOEEncoder(**params)\n",
    "\n",
    "\n",
    "def instantiate_robust_scaler(trial: Trial) -> RobustScaler:\n",
    "    params = {\n",
    "        \"with_centering\": trial.suggest_categorical(\"with_centering\", [True, False]),\n",
    "        \"with_scaling\": trial.suggest_categorical(\"with_scaling\", [True, False]),\n",
    "    }\n",
    "    return RobustScaler(**params)\n",
    "\n",
    "\n",
    "def instantiate_extra_trees(trial: Trial, warm_start=False) -> ExtraTreesClassifier:\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
    "        \"max_features\": trial.suggest_float(\"max_features\", 0, 1),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    return ExtraTreesClassifier(**params, warm_start=warm_start)\n",
    "\n",
    "\n",
    "def instantiate_logistic_regression(trial) -> LogisticRegression:\n",
    "    solver = trial.suggest_categorical(\n",
    "        \"solver\", [\"lbfgs\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]\n",
    "    )\n",
    "    if solver == \"newton-cholesky\":\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l2\", None])\n",
    "        params = {\n",
    "            \"solver\": solver,\n",
    "            \"penalty\": penalty,\n",
    "            \"C\": trial.suggest_float(\"C\", 0.0, 10.0),\n",
    "        }\n",
    "    elif solver == \"lbfgs\":\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l2\", None])\n",
    "        params = {\n",
    "            \"solver\": solver,\n",
    "            \"penalty\": penalty,\n",
    "            \"C\": trial.suggest_float(\"C\", 0.0, 10.0),\n",
    "        }\n",
    "    elif solver == \"liblinear\":\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"])\n",
    "        params = {\n",
    "            \"solver\": solver,\n",
    "            \"penalty\": penalty,\n",
    "            \"C\": trial.suggest_float(\"C\", 0.0, 10.0),\n",
    "        }\n",
    "    elif solver == \"newton-cg\":\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l2\", None])\n",
    "        params = {\n",
    "            \"solver\": solver,\n",
    "            \"penalty\": penalty,\n",
    "            \"C\": trial.suggest_float(\"C\", 0.0, 10.0),\n",
    "        }\n",
    "    elif solver == \"sag\":\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l2\", None])\n",
    "        params = {\n",
    "            \"solver\": solver,\n",
    "            \"penalty\": penalty,\n",
    "            \"C\": trial.suggest_float(\"C\", 0.0, 10.0),\n",
    "        }\n",
    "    elif solver == \"saga\":\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l2\", None])\n",
    "        params = {\n",
    "            \"solver\": solver,\n",
    "            \"penalty\": penalty,\n",
    "            \"C\": trial.suggest_float(\"C\", 0.0, 10.0),\n",
    "        }\n",
    "    return LogisticRegression(**params)\n",
    "\n",
    "\n",
    "#def instantiate_lgbm_classifier(trial):\n",
    "#    params = {\n",
    "#        \"boosting_type\": trial.suggest_categorical(\n",
    "#            \"boosting_type\", [\"gbdt\", \"dart\", \"rf\"]\n",
    "#        ),\n",
    "#        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 64),\n",
    "#        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 20),\n",
    "#        \"n_estimators\": trial.suggest_int(\"n_estimators\", 35, 150),\n",
    "#        \"class_weight\": \"balanced\",    }\n",
    "#    return LGBMClassifier(**params)\n",
    "\n",
    "\n",
    "\n",
    "def instantiate_lgbm_classifier(trial):\n",
    "    params = {\n",
    "        \"boosting_type\": trial.suggest_categorical(\n",
    "            \"boosting_type\", [\"gbdt\", \"dart\"]#, #\"rf\"]\n",
    "        ),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 64),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 20),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 35, 150),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        # Add the following conditional logic for bagging parameters\n",
    "        #\"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10) if params[\"boosting_type\"] == \"rf\" else 1,  # Ensure bagging_freq > 0 for 'rf'\n",
    "        #\"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 0.99) if params[\"boosting_type\"] == \"rf\" else 1.0,  # Ensure 0 < bagging_fraction < 1 for 'rf'\n",
    "        #\"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.1, 0.99) if params[\"boosting_type\"] != \"rf\" else 1.0,  # Ensure 0 < feature_fraction < 1 for non-'rf'\n",
    "    }\n",
    "    return LGBMClassifier(**params,verbose=-1)\n",
    "\n",
    "def instantiate_xgboost(trial):\n",
    "    params = {\n",
    "         \"objective\": trial.suggest_categorical(\n",
    "    \"objective\", [\"binary:hinge\", \"binary:logistic\"]),\n",
    "    \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\", \"gblinear\"]),\n",
    "    \"max_leaves\": trial.suggest_int(\"max_leaves\",1, 10, 10),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\",3, 15, 4),\n",
    "    \"grow_policy\": trial.suggest_categorical(\"grow_policy\",[\"depthwise\"]),\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\",50, 100),\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 1),\n",
    "}\n",
    "    return XGBClassifier(**params)\n",
    "    \n",
    "\n",
    "\n",
    "def instantiate_random_forest(trial):\n",
    "    params = {\n",
    "        \"criterion\": trial.suggest_categorical(\n",
    "            \"criterion\", [\"gini\", \"entropy\", \"log_loss\"]\n",
    "        ),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 64),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 64),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 35, 150),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        \"class_weight\": trial.suggest_categorical(\n",
    "            \"class_weight\", [\"balanced\", \"balanced_subsample\"]\n",
    "        ),\n",
    "        \"max_features\": trial.suggest_categorical(\n",
    "            \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "        ),\n",
    "    }\n",
    "    return RandomForestClassifier(**params)\n",
    "\n",
    "\n",
    "#def instantiate_random_forest(trial):\n",
    "\n",
    "    # \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    # \"max_depth\": list(range(1, 11)),\n",
    "    # \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "\n",
    "    #n_estimators = trial.suggest_int(\"n_estimators\", 10, 100)\n",
    "    #max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "    #criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    \n",
    "   # clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion)\n",
    "    #return clf\n",
    "\n",
    "\n",
    "def model_selector(clf_string, trial: Trial):\n",
    "    if clf_string == \"logistic_regression\":\n",
    "        model = instantiate_logistic_regression(trial)\n",
    "    elif clf_string == \"random_forest\":\n",
    "        model = instantiate_random_forest(trial)\n",
    "    elif clf_string == \"extra_trees\":\n",
    "        model = instantiate_extra_trees(trial)\n",
    "    elif clf_string == \"lightgbm\":\n",
    "        model = instantiate_lgbm_classifier(trial)\n",
    "    elif clf_string=='xgboost':\n",
    "        model = instantiate_xgboost(trial)\n",
    "\n",
    "    return model\n",
    "\n",
    "def instantiate_numerical_pipeline(trial : Trial) -> Pipeline:\n",
    "  pipeline = Pipeline([\n",
    "    ('imputer', instantiate_numerical_simple_imputer(trial)),\n",
    "    ('scaler', instantiate_robust_scaler(trial))\n",
    "  ])\n",
    "  return pipeline\n",
    "\n",
    "def instantiate_categorical_pipeline(trial : Trial) -> Pipeline:\n",
    "  pipeline = Pipeline([\n",
    "    ('imputer', instantiate_categorical_simple_imputer(trial)),\n",
    "    ('encoder', instantiate_woe_encoder(trial))\n",
    "  ])\n",
    "  return pipeline\n",
    "\n",
    "def instantiate_processor(trial : Trial, numerical_columns : list[str], categorical_columns : list[str]) -> ColumnTransformer:\n",
    "\n",
    "  numerical_pipeline = instantiate_numerical_pipeline(trial)\n",
    "  categorical_pipeline = instantiate_categorical_pipeline(trial)\n",
    "\n",
    "  processor = ColumnTransformer([\n",
    "    ('numerical_pipeline', numerical_pipeline, numerical_columns),\n",
    "    ('categorical_pipeline', categorical_pipeline, categorical_columns)\n",
    "  ])\n",
    "\n",
    "  return processor\n",
    "\n",
    "\n",
    "\n",
    "def instantiate_model(classifier, trial : Trial, numerical_columns : list[str], categorical_columns : list[str]) -> Pipeline:\n",
    "\n",
    "  processor = instantiate_processor(\n",
    "    trial, numerical_columns, categorical_columns\n",
    "  )\n",
    "  \n",
    "  clf = model_selector(classifier,trial)\n",
    "\n",
    "  model = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('classifier', clf)\n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKavWOTGuwME"
   },
   "source": [
    "Now let's define the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9Xp9WCzhuwME"
   },
   "outputs": [],
   "source": [
    "def objective(classifier, trial : Trial, X : DataFrame, y : np.ndarray | Series, numerical_columns : Optional[list[str]]=None, categorical_columns : Optional[list[str]]=None, random_state : int=42) -> float:\n",
    "  if numerical_columns is None:\n",
    "    numerical_columns = [\n",
    "      *x.select_dtypes(exclude=['object', 'category']).columns\n",
    "    ]\n",
    "\n",
    "  if categorical_columns is None:\n",
    "    categorical_columns = [\n",
    "      *x.select_dtypes(include=['object', 'category']).columns\n",
    "    ]\n",
    "\n",
    "  model = instantiate_model(classifier,trial, numerical_columns, categorical_columns)\n",
    "\n",
    "  kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "  roc_auc_scorer = make_scorer(roc_auc_score, response_method='predict')# can also be \"predict_proba\", or None \"#needs_proba=True)\n",
    "  scores = cross_val_score(model, X, y, scoring=roc_auc_scorer, cv=kf)\n",
    "\n",
    "  return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ojKtSwOuuwMF"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please set either 'minimize' or 'maximize' to direction. You can also set the corresponding `StudyDirection` member.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m model_specifications \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classifier \u001b[38;5;129;01min\u001b[39;00m classifiers:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#study: Study = create_study(study_name=\"optimization\", direction=\"maximize\")\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     study \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpruner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSuccessiveHalvingPruner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(classifier, trial, x_train, np\u001b[38;5;241m.\u001b[39marray(y_train)\u001b[38;5;241m.\u001b[39mravel()),\n\u001b[1;32m     15\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     16\u001b[0m     )  \u001b[38;5;66;03m# n_trials=100 is the original value\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     model_specifications[classifier]\u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/_convert_positional_args.py:83\u001b[0m, in \u001b[0;36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     81\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(inferred_kwargs)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/study.py:1254\u001b[0m, in \u001b[0;36mcreate_study\u001b[0;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of objectives must be greater than 0.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1251\u001b[0m     d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, StudyDirection\u001b[38;5;241m.\u001b[39mMINIMIZE, StudyDirection\u001b[38;5;241m.\u001b[39mMAXIMIZE]\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m directions\n\u001b[1;32m   1253\u001b[0m ):\n\u001b[0;32m-> 1254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to direction. You can also set the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding `StudyDirection` member.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1257\u001b[0m     )\n\u001b[1;32m   1259\u001b[0m direction_objects \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1260\u001b[0m     d \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d, StudyDirection) \u001b[38;5;28;01melse\u001b[39;00m StudyDirection[d\u001b[38;5;241m.\u001b[39mupper()] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m directions\n\u001b[1;32m   1261\u001b[0m ]\n\u001b[1;32m   1263\u001b[0m storage \u001b[38;5;241m=\u001b[39m storages\u001b[38;5;241m.\u001b[39mget_storage(storage)\n",
      "\u001b[0;31mValueError\u001b[0m: Please set either 'minimize' or 'maximize' to direction. You can also set the corresponding `StudyDirection` member."
     ]
    }
   ],
   "source": [
    "classifiers: list[str] = [\"logistic_regression\", \"extra_trees\", \"random_forest\"]\n",
    "\n",
    "model_performance = pd.DataFrame()\n",
    "model_specifications = dict()\n",
    "\n",
    "for classifier in classifiers:\n",
    "    #study: Study = create_study(study_name=\"optimization\", direction=\"maximize\")\n",
    "    study = create_study(\n",
    "    direction=\"optimization\",\n",
    "    pruner=SuccessiveHalvingPruner(reduction_factor=2),\n",
    "    sampler=RandomSampler(seed=42),\n",
    ")\n",
    "    study.optimize(\n",
    "        lambda trial: objective(classifier, trial, x_train, np.array(y_train).ravel()),\n",
    "        n_trials=3,\n",
    "    )  # n_trials=100 is the original value\n",
    "\n",
    "  \n",
    "\n",
    "    model_specifications[classifier]= study.best_params\n",
    "\n",
    "\n",
    "    best_trial: FrozenTrial = study.best_trial\n",
    "    model: Pipeline = instantiate_model(\n",
    "        classifier,\n",
    "        trial=best_trial,\n",
    "        numerical_columns=numerical_columns,\n",
    "        categorical_columns=categorical_columns,\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    model_performance[classifier] = calculate_model_statistics(y_test, predictions)\n",
    "    model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9Ki-PXUG6yL"
   },
   "source": [
    "These models are performing really poorly so far, with both the Matthews Correlation Coefficient and ROC-AUC pointing to the modeling being no better than random guessing then it comes to predicting on defaults. Let's see how well the lightgbm and xgboost classifiers perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 21:07:59,693] A new study created in memory with name: no-name-9087b42b-7ac7-48d1-955c-b5d8ca1be031\n",
      "[I 2024-12-20 21:08:15,231] Trial 0 finished with value: 0.6821264376779052 and parameters: {'numerical_strategy': 'median', 'with_centering': True, 'with_scaling': False, 'categorical_strategy': 'constant', 'sigma': 0.10390188698471643, 'regularization': 4.8495492608099715, 'randomized': True, 'boosting_type': 'dart', 'num_leaves': 21, 'max_depth': 10, 'n_estimators': 85}. Best is trial 0 with value: 0.6821264376779052.\n",
      "[I 2024-12-20 21:08:19,043] A new study created in memory with name: no-name-24058bba-2685-4e4d-a92c-cf3046339651\n",
      "/tmp/ipykernel_8780/3211020520.py:131: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/distributions.py:708: UserWarning:\n",
      "\n",
      "The distribution is specified by [1, 10] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
      "\n",
      "/tmp/ipykernel_8780/3211020520.py:132: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2024-12-20 21:16:23,521] Trial 0 finished with value: 0.5 and parameters: {'numerical_strategy': 'median', 'with_centering': True, 'with_scaling': False, 'categorical_strategy': 'constant', 'sigma': 0.10390188698471643, 'regularization': 4.8495492608099715, 'randomized': True, 'objective': 'binary:logistic', 'booster': 'dart', 'max_leaves': 1, 'max_depth': 7, 'grow_policy': 'depthwise', 'n_estimators': 81, 'learning_rate': 0.14809892204552141}. Best is trial 0 with value: 0.5.\n",
      "/tmp/ipykernel_8780/3211020520.py:131: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/distributions.py:708: UserWarning:\n",
      "\n",
      "The distribution is specified by [1, 10] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
      "\n",
      "/tmp/ipykernel_8780/3211020520.py:132: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers: list[str] = [\"lightgbm\",\n",
    "                          \"xgboost\"]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    #study = create_study(study_name=\"optimization\", direction=\"maximize\")\n",
    "\n",
    "    study = create_study(\n",
    "        direction=\"maximize\",\n",
    "        pruner=SuccessiveHalvingPruner(reduction_factor=2),\n",
    "        sampler=RandomSampler(seed=42),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    study.optimize(\n",
    "        lambda trial: objective(classifier, trial, x_train, np.array(y_train).ravel()),\n",
    "        n_trials=4,\n",
    "    )  # n_trials=100 is the original value\n",
    "\n",
    "    model_specifications[classifier]= study.best_params\n",
    "\n",
    "\n",
    "    best_trial: FrozenTrial = study.best_trial\n",
    "    model: Pipeline = instantiate_model(\n",
    "        classifier,\n",
    "        trial=best_trial,\n",
    "        numerical_columns=numerical_columns,\n",
    "        categorical_columns=categorical_columns,\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions: NDArray = model.predict(x_test)\n",
    "    model_performance[classifier] = calculate_model_statistics(y_test, predictions)\n",
    "    model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xgboost_with_nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.686212</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_correlation</th>\n",
       "      <td>0.214935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_beta</th>\n",
       "      <td>0.515161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.163206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.677497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.686212</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lightgbm  xgboost  xgboost_with_nulls\n",
       "roc_auc               0.686212      0.5            0.500662\n",
       "matthews_correlation  0.214935      0.0            0.022829\n",
       "f_beta                0.515161      0.0            0.001627\n",
       "precision             0.163206      0.0            0.473684\n",
       "recall                0.677497      0.0            0.001465\n",
       "balanced_accuracy     0.686212      0.5            0.500662"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the above code with successive halving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(\n",
    "    classifier_string: str, trial: Trial, X: DataFrame, y: DataFrame, seed: int = 42\n",
    ") -> Optional[float]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, shuffle=True, random_state=seed\n",
    "    )\n",
    "    # model = instantiate_model(classifier=classifier_string,trial=trial, numerical_columns=numerical_columns, categorical_columns=categorical_columns)\n",
    "    model = model_selector(\n",
    "        classifier_string, trial\n",
    "    )  # instantiate_extra_trees(trial, warm_start=True)\n",
    "    n_estimators = model.get_params().get(\"n_estimators\")\n",
    "    min_estimators = 45\n",
    "\n",
    "    for num_estimators in range(min_estimators, n_estimators + 1):\n",
    "        model.set_params(n_estimators=num_estimators)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        trial.report(score, num_estimators)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            pass  # raise TrialPruned()\n",
    "\n",
    "    kfold = KFold(shuffle=True, random_state=seed)\n",
    "    roc_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    scores = cross_val_score(model, X, y, cv=kfold, scoring=roc_auc)\n",
    "\n",
    "    return np.min([np.mean(scores), np.median(scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 21:28:01,617] A new study created in memory with name: no-name-0482393f-3b9f-42fa-b66d-24f8fa86297d\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:28:14,921] Trial 0 finished with value: 0.7096859552111667 and parameters: {'boosting_type': 'dart', 'num_leaves': 48, 'max_depth': 12, 'n_estimators': 53}. Best is trial 0 with value: 0.7096859552111667.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:30:04,511] Trial 1 finished with value: 0.7137132522553553 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 56, 'max_depth': 12, 'n_estimators': 117}. Best is trial 1 with value: 0.7137132522553553.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:30:16,402] Trial 2 finished with value: 0.700659942847163 and parameters: {'boosting_type': 'dart', 'num_leaves': 54, 'max_depth': 3, 'n_estimators': 56}. Best is trial 1 with value: 0.7137132522553553.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:30:50,567] Trial 3 finished with value: 0.7111691730240007 and parameters: {'boosting_type': 'dart', 'num_leaves': 35, 'max_depth': 8, 'n_estimators': 68}. Best is trial 1 with value: 0.7137132522553553.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:31:36,473] Trial 4 finished with value: 0.715615546209345 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 20, 'max_depth': 7, 'n_estimators': 87}. Best is trial 4 with value: 0.715615546209345.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:31:41,031] Trial 5 finished with value: 0.711312061601022 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 34, 'max_depth': 12, 'n_estimators': 40}. Best is trial 4 with value: 0.715615546209345.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:33:17,579] Trial 6 finished with value: 0.7150526353374292 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 6, 'max_depth': 19, 'n_estimators': 147}. Best is trial 4 with value: 0.715615546209345.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:33:55,389] Trial 7 finished with value: 0.7126257744065994 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 8, 'max_depth': 14, 'n_estimators': 86}. Best is trial 4 with value: 0.715615546209345.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:34:13,310] Trial 8 finished with value: 0.6942273134748521 and parameters: {'boosting_type': 'dart', 'num_leaves': 4, 'max_depth': 19, 'n_estimators': 65}. Best is trial 4 with value: 0.715615546209345.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:34:29,879] Trial 9 finished with value: 0.7143841743123585 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 34, 'max_depth': 11, 'n_estimators': 56}. Best is trial 4 with value: 0.715615546209345.\n"
     ]
    }
   ],
   "source": [
    "numerical_train = application_train.clone()\n",
    "encoder_mapping_key = dict()\n",
    "for col in numerical_train.columns:\n",
    "    try:\n",
    "        key: dict[str, int] = create_encoder_mapping(numerical_train, col)\n",
    "        numerical_train = encode_feature(numerical_train, col, key)\n",
    "        encoder_mapping_key[col] = key\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "x = numerical_train.drop(\"target\")\n",
    "y = numerical_train[\"target\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True)\n",
    "\n",
    "study = create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=SuccessiveHalvingPruner(reduction_factor=2),\n",
    "    sampler=RandomSampler(seed=42),\n",
    ")\n",
    "study.optimize(\n",
    "    lambda trial: objective(\"lightgbm\", trial, x, y), n_trials=10\n",
    ")  # 30 trials is 12m 35.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'num_leaves': 56,\n",
       " 'max_depth': 12,\n",
       " 'n_estimators': 117}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_specifications['lgbm_with_nulls']= study.best_params\n",
    "\n",
    "lbgm_no_nulls=LGBMClassifier(**study.best_params)\n",
    "lbgm_no_nulls.fit(x_train, y_train)\n",
    "predictions = lbgm_no_nulls.predict(x_test)\n",
    "model_performance[\"lgbm_with_nulls\"] = calculate_model_statistics(y_test, predictions)\n",
    "model_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 21:35:16,736] A new study created in memory with name: no-name-eb22636c-f830-43eb-9812-45a0ac427e08\n",
      "/tmp/ipykernel_8780/3211020520.py:131: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/distributions.py:708: UserWarning:\n",
      "\n",
      "The distribution is specified by [1, 10] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
      "\n",
      "/tmp/ipykernel_8780/3211020520.py:132: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:35:39,705] Trial 0 finished with value: 0.5 and parameters: {'objective': 'binary:logistic', 'booster': 'gbtree', 'max_leaves': 1, 'max_depth': 3, 'grow_policy': 'depthwise', 'n_estimators': 52, 'learning_rate': 0.8675143843171859}. Best is trial 0 with value: 0.5.\n",
      "/tmp/ipykernel_8780/3211020520.py:131: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/distributions.py:708: UserWarning:\n",
      "\n",
      "The distribution is specified by [1, 10] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
      "\n",
      "/tmp/ipykernel_8780/3211020520.py:132: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-20 21:44:22,289] Trial 1 finished with value: 0.5 and parameters: {'objective': 'binary:logistic', 'booster': 'dart', 'max_leaves': 1, 'max_depth': 3, 'grow_policy': 'depthwise', 'n_estimators': 59, 'learning_rate': 0.1915704647548995}. Best is trial 0 with value: 0.5.\n",
      "/tmp/ipykernel_8780/3211020520.py:131: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/distributions.py:708: UserWarning:\n",
      "\n",
      "The distribution is specified by [1, 10] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
      "\n",
      "/tmp/ipykernel_8780/3211020520.py:132: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:34] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:51] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:54] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:44:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:07] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:11] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "[I 2024-12-20 21:45:12,803] Trial 2 finished with value: 0.6933485202574599 and parameters: {'objective': 'binary:logistic', 'booster': 'gblinear', 'max_leaves': 1, 'max_depth': 3, 'grow_policy': 'depthwise', 'n_estimators': 64, 'learning_rate': 0.37269822486075477}. Best is trial 2 with value: 0.6933485202574599.\n",
      "/tmp/ipykernel_8780/3211020520.py:131: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/distributions.py:708: UserWarning:\n",
      "\n",
      "The distribution is specified by [1, 10] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
      "\n",
      "/tmp/ipykernel_8780/3211020520.py:132: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:51] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:58] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:45:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:26] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n",
      "[I 2024-12-20 21:46:49,747] Trial 3 finished with value: 0.6929007098048827 and parameters: {'objective': 'binary:logistic', 'booster': 'gblinear', 'max_leaves': 1, 'max_depth': 3, 'grow_policy': 'depthwise', 'n_estimators': 80, 'learning_rate': 0.17881888245041863}. Best is trial 2 with value: 0.6933485202574599.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n",
      "\n",
      "[21:46:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"grow_policy\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xgboost_with_nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.686212</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_correlation</th>\n",
       "      <td>0.214935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_beta</th>\n",
       "      <td>0.515161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.163206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.677497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.686212</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lightgbm  xgboost  xgboost_with_nulls\n",
       "roc_auc               0.686212      0.5            0.500662\n",
       "matthews_correlation  0.214935      0.0            0.022829\n",
       "f_beta                0.515161      0.0            0.001627\n",
       "precision             0.163206      0.0            0.473684\n",
       "recall                0.677497      0.0            0.001465\n",
       "balanced_accuracy     0.686212      0.5            0.500662"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=SuccessiveHalvingPruner(reduction_factor=2),\n",
    "    sampler=RandomSampler(seed=42),\n",
    ")\n",
    "study.optimize(\n",
    "    lambda trial: objective(\"xgboost\", trial, x, y), n_trials=4\n",
    ")\n",
    "\n",
    "xgb_no_nulls=XGBClassifier(**study.best_params)\n",
    "xgb_no_nulls.fit(x_train, y_train)\n",
    "predictions = xgb_no_nulls.predict(x_test)\n",
    "model_performance[\"xgboost_with_nulls\"] = calculate_model_statistics(y_test, predictions)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE Oversampling \n",
    "One way to strengthen our model performance could be to oversample/undersample on our dataset to rebalance the proportion of positive and negative target classes, and then train our classifier on that. We'll use the method put forth in the original SMOTE paper and then retrain on the models shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "oversampling = SMOTE(sampling_strategy=0.1)\n",
    "undersampling = RandomUnderSampler(sampling_strategy=0.5)\n",
    "\n",
    "steps = [(\"oversample\", oversampling), (\"undersample\", undersampling)]\n",
    "pipeline = ImbPipeline(steps=steps)\n",
    "smote_x, smote_y = pipeline.fit_resample(x, y)\n",
    "\n",
    "pca = PCA(n_components=smote_x.shape[1])\n",
    "smote_x = pca.fit_transform(smote_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    smote_x, smote_y, stratify=smote_y, random_state=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created our smote dataset, we can fit the models. However our previous model specifications aren't as helpful since the dataset is new, and models may perform better on different hyperparameters. Let's create another study and run it again! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-17 23:13:37,310] A new study created in memory with name: no-name-f274b13d-68ed-4537-8fcf-2a06fcac1e27\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-17 23:13:49,852] Trial 0 finished with value: 0.7101552933890023 and parameters: {'boosting_type': 'dart', 'num_leaves': 48, 'max_depth': 12, 'n_estimators': 53}. Best is trial 0 with value: 0.7101552933890023.\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[I 2024-12-17 23:15:34,958] Trial 1 finished with value: 0.7145099764014973 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 56, 'max_depth': 12, 'n_estimators': 117}. Best is trial 1 with value: 0.7145099764014973.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>extra_trees</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xgb_with_nulls</th>\n",
       "      <th>xgboost_with_nulls</th>\n",
       "      <th>SMOTE_lgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.500772</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.614881</td>\n",
       "      <td>0.503748</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.628378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_correlation</th>\n",
       "      <td>0.023344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208138</td>\n",
       "      <td>0.053637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_beta</th>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304293</td>\n",
       "      <td>0.009254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250323</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311762</td>\n",
       "      <td>0.008345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.500772</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.614881</td>\n",
       "      <td>0.503748</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.628378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      logistic_regression  extra_trees  random_forest  \\\n",
       "roc_auc                          0.500772          0.5       0.614881   \n",
       "matthews_correlation             0.023344          0.0       0.208138   \n",
       "f_beta                           0.001939          0.0       0.304293   \n",
       "precision                        0.433333          0.0       0.250323   \n",
       "recall                           0.001745          0.0       0.311762   \n",
       "balanced_accuracy                0.500772          0.5       0.614881   \n",
       "\n",
       "                      lightgbm  xgboost  xgb_with_nulls  xgboost_with_nulls  \\\n",
       "roc_auc               0.503748      0.5             0.5                 0.5   \n",
       "matthews_correlation  0.053637      0.0             0.0                 0.0   \n",
       "f_beta                0.009254      0.0             0.0                 0.0   \n",
       "precision             0.464286      0.0             0.0                 0.0   \n",
       "recall                0.008345      0.0             0.0                 0.0   \n",
       "balanced_accuracy     0.503748      0.5             0.5                 0.5   \n",
       "\n",
       "                      SMOTE_lgbm  \n",
       "roc_auc                 0.628378  \n",
       "matthews_correlation    0.309718  \n",
       "f_beta                  0.375642  \n",
       "precision               0.636660  \n",
       "recall                  0.359276  \n",
       "balanced_accuracy       0.628378  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=SuccessiveHalvingPruner(reduction_factor=2),\n",
    "    sampler=RandomSampler(seed=42),\n",
    ")\n",
    "study.optimize(lambda trial: objective(\"lightgbm\", trial, x, y), n_trials=2)\n",
    "\n",
    "\n",
    "model_specifications[\"SMOTE_lgbm\"] = study.best_params\n",
    "\n",
    "smote_lgbm = LGBMClassifier(**study.best_params)\n",
    "smote_lgbm.fit(x_train, y_train)\n",
    "predictions = smote_lgbm.predict(x_test)\n",
    "model_performance[\"SMOTE_lgbm\"] = calculate_model_statistics(y_test, predictions)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 15:24:36,569] A new study created in memory with name: no-name-da9ced53-ef4d-4183-8464-54a0dc9ea5e1\n",
      "/tmp/ipykernel_8780/3211020520.py:131: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/distributions.py:708: UserWarning:\n",
      "\n",
      "The distribution is specified by [1, 10] and step=10, but the range is not divisible by `step`. It will be replaced by [1, 1].\n",
      "\n",
      "/tmp/ipykernel_8780/3211020520.py:132: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning:\n",
      "\n",
      "The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "\n",
      "[W 2024-12-20 15:24:45,720] Trial 0 failed with parameters: {'numerical_strategy': 'median', 'with_centering': True, 'with_scaling': False, 'categorical_strategy': 'constant', 'sigma': 0.10390188698471643, 'regularization': 4.8495492608099715, 'randomized': True, 'objective': 'binary:logistic', 'booster': 'dart', 'max_leaves': 1, 'max_depth': 7, 'grow_policy': 'depthwise', 'n_estimators': 81, 'learning_rate': 0.14809892204552141} because of the following error: ValueError('\\nAll the 5 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n5 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\\n    return fit_method(estimator, *args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 469, in fit\\n    Xt = self._fit(X, y, routed_params)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 406, in _fit\\n    X, fitted_transformer = fit_transform_one_cached(\\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\\n    return self.func(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\\n    data_to_wrap = f(self, X, *args, **kwargs)\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\\n    return fit_method(estimator, *args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\\n    result = self._call_func_on_transformers(\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\\n    return Parallel(n_jobs=self.n_jobs)(jobs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\\n    return super().__call__(iterable_with_config)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\\n    return output if self.return_generator else list(output)\\n                                                ^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\\n    res = func(*args, **kwargs)\\n          ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\\n    return self.function(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\\n    return fit_method(estimator, *args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 541, in fit_transform\\n    return last_step.fit_transform(\\n           ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\\n    data_to_wrap = f(self, X, *args, **kwargs)\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 474, in fit_transform\\n    return self.fit(X, y, **fit_params).transform(X, y)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 298, in fit\\n    X, y = convert_inputs(X, y)\\n           ^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 89, in convert_inputs\\n    raise ValueError(msg)\\nValueError: `X` and `y` both have indexes, but they do not match. If you are shuffling your input data on purpose (e.g. via permutation_test_score) use np arrays instead of data frames / series\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8780/3376653665.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: objective(\"xgboost\", trial, x, y), n_trials=2)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8780/3992172243.py\", line 16, in objective\n",
      "    scores = cross_val_score(model, X, y, scoring=roc_auc_scorer, cv=kf)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 712, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 443, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 529, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
      "    result = self._call_func_on_transformers(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 541, in fit_transform\n",
      "    return last_step.fit_transform(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 474, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 298, in fit\n",
      "    X, y = convert_inputs(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 89, in convert_inputs\n",
      "    raise ValueError(msg)\n",
      "ValueError: `X` and `y` both have indexes, but they do not match. If you are shuffling your input data on purpose (e.g. via permutation_test_score) use np arrays instead of data frames / series\n",
      "\n",
      "[W 2024-12-20 15:24:45,720] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n    result = self._call_func_on_transformers(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 541, in fit_transform\n    return last_step.fit_transform(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 474, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 298, in fit\n    X, y = convert_inputs(X, y)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 89, in convert_inputs\n    raise ValueError(msg)\nValueError: `X` and `y` both have indexes, but they do not match. If you are shuffling your input data on purpose (e.g. via permutation_test_score) use np arrays instead of data frames / series\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m create_study(\n\u001b[1;32m      2\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     pruner\u001b[38;5;241m=\u001b[39mSuccessiveHalvingPruner(reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      4\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mRandomSampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m smote_xgb \u001b[38;5;241m=\u001b[39m XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstudy\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m      9\u001b[0m smote_xgb\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m create_study(\n\u001b[1;32m      2\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     pruner\u001b[38;5;241m=\u001b[39mSuccessiveHalvingPruner(reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      4\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mRandomSampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m smote_xgb \u001b[38;5;241m=\u001b[39m XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstudy\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m      9\u001b[0m smote_xgb\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(classifier, trial, X, y, numerical_columns, categorical_columns, random_state)\u001b[0m\n\u001b[1;32m     14\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m     15\u001b[0m roc_auc_scorer \u001b[38;5;241m=\u001b[39m make_scorer(roc_auc_score, needs_proba\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroc_auc_scorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin([np\u001b[38;5;241m.\u001b[39mmean(scores), np\u001b[38;5;241m.\u001b[39mmedian([scores])])\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n    result = self._call_func_on_transformers(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 541, in fit_transform\n    return last_step.fit_transform(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 474, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 298, in fit\n    X, y = convert_inputs(X, y)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/category_encoders/utils.py\", line 89, in convert_inputs\n    raise ValueError(msg)\nValueError: `X` and `y` both have indexes, but they do not match. If you are shuffling your input data on purpose (e.g. via permutation_test_score) use np arrays instead of data frames / series\n"
     ]
    }
   ],
   "source": [
    "study = create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=SuccessiveHalvingPruner(reduction_factor=2),\n",
    "    sampler=RandomSampler(seed=42),\n",
    ")\n",
    "study.optimize(lambda trial: objective(\"xgboost\", trial, x, y), n_trials=2)\n",
    "\n",
    "smote_xgb = XGBClassifier(**study.best_params)\n",
    "smote_xgb.fit(x_train, y_train)\n",
    "predictions = smote_xgb.predict(x_test)\n",
    "model_performance[\"SMOTE_xgb\"] = calculate_model_statistics(y_test, predictions)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01sF7EPMG6yL"
   },
   "source": [
    "## Code for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_extra_trees(trial: Trial, warm_start=False) -> ExtraTreesClassifier:\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
    "        \"max_features\": trial.suggest_float(\"max_features\", 0, 1),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    return ExtraTreesClassifier(**params, warm_start=warm_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMote, but with previous lgbm no nulls model specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_lgbm = LGBMClassifier(**model_specifications[\"lgbm_with_nulls\"], verbose=-1)\n",
    "smote_lgbm.fit(x_train, y_train)\n",
    "\n",
    "y_predict = smote_lgbm.predict(x_test)\n",
    "\n",
    "smote_performance: tuple[DataFrame] = calculate_model_statistics(y_test, y_predict)\n",
    "model_performance[\"SMOTE_lgbm\"] = smote_performance\n",
    "\n",
    "\n",
    "pd.concat(\n",
    "    [model_performance[\"lightgbm\"], smote_performance],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_sgd_classifier(trial, random_state=0):\n",
    "    params = {\n",
    "        \"loss\": trial.suggest_categorical(\n",
    "            \"loss\",\n",
    "            [\n",
    "                \"hinge\",\n",
    "                \"log_loss\",\n",
    "                \"modified_huber\",\n",
    "                \"squared_hinge\",\n",
    "                \"perceptron\",\n",
    "                \"squared_error\",\n",
    "                \"huber\",\n",
    "                \"epsilon_insensitive\",\n",
    "                \"squared_epsilon_insensitive\",\n",
    "            ],\n",
    "        ), \"penalty\": trial.suggest_categorical('penalty',['l2','l1', 'elasticnet', None]),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\",0.0, 1000),\n",
    "        \"l1_ratio\": trial.suggest_float(\"l1_ratio\",0.0, 1.0)}\n",
    "    return SGDClassifier(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the features manually to start\n",
    "encoder_mapping_key = dict()\n",
    "for col in application_train.columns:\n",
    "    try:\n",
    "        key: dict[str, int] = create_encoder_mapping(application_train, col)\n",
    "        numerical_train = encode_feature(application_train, col, key)\n",
    "        encoder_mapping_key[col] = key\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "x = numerical_train.drop(\"target\")\n",
    "y = numerical_train[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "_XN9JpguG6yL"
   },
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "from sklego.preprocessing import ColumnSelector\n",
    "\n",
    "\n",
    "def choose_columns(trial : Trial, columns : list[str]) -> list[str]:\n",
    "  choose = lambda column: trial.suggest_categorical(column, [True, False])\n",
    "  choices = [*filter(choose, columns)]\n",
    "  return choices\n",
    "\n",
    "\n",
    "def instantiate_column_selector(trial : Trial, columns : list[str]) -> ColumnSelector:\n",
    "  choose = lambda column: trial.suggest_categorical(column, [True, False])\n",
    "  choices = [*filter(choose, columns)]\n",
    "  selector = ColumnSelector(choices)\n",
    "  return selector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "qcjkI0cKG6yL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "\n",
    "Classifier = (\n",
    "    RandomForestClassifier\n",
    "    | ExtraTreesClassifier\n",
    "    | SVC\n",
    "    | LogisticRegression\n",
    "    | KNeighborsClassifier\n",
    ")\n",
    "\n",
    "\n",
    "def instantiate_learner(trial: Trial) -> Classifier:\n",
    "    algorithm = trial.suggest_categorical(\n",
    "        \"algorithm\", [\"logistic\", \"forest\", \"extra_forest\", \"lgbm\"]\n",
    "    )\n",
    "    if algorithm == \"logistic\":\n",
    "        model = instantiate_logistic_regression(trial)\n",
    "    elif algorithm == \"forest\":\n",
    "        model = instantiate_random_forest(trial)\n",
    "    elif algorithm == \"extra_forest\":\n",
    "        model = instantiate_extra_trees(trial)\n",
    "    elif algorithm == \"lgbm\":\n",
    "        model = instantiate_lgbm_classifier(trial)\n",
    "    # elif algorithm=='knn':\n",
    "    #  model = instantiate_knn(trial)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def instantiate_scaler(trial):\n",
    "    scaler_type = trial.suggest_categorical(\n",
    "        \"scaler_type\", [\"standard\", \"minmax\", \"robust\"]\n",
    "    )\n",
    "\n",
    "    if scaler_type == \"standard\":\n",
    "        params = {\n",
    "            \"with_mean\": trial.suggest_categorical(\"with_mean\", [True, False]),\n",
    "            \"with_std\": trial.suggest_categorical(\"with_std\", [True, False]),\n",
    "        }\n",
    "        scaler = StandardScaler(**params)\n",
    "\n",
    "    elif scaler_type == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "    elif scaler_type == \"robust\":\n",
    "        params = {\n",
    "            \"with_centering\": trial.suggest_categorical(\n",
    "                \"with_centering\", [True, False]\n",
    "            ),\n",
    "            \"with_scaling\": trial.suggest_categorical(\"with_std\", [True, False]),\n",
    "        }\n",
    "        scaler = RobustScaler(**params)\n",
    "\n",
    "    return scaler\n",
    "\n",
    "#def instantiate_encoder(trial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial : Trial, x : DataFrame, y : DataFrame, seed : int=42):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, shuffle=True, random_state=seed\n",
    "    )\n",
    "    \n",
    "    model = instantiate_extra_trees(trial, warm_start=True)\n",
    "    n_estimators = model.get_params().get('n_estimators')\n",
    "    min_estimators = 100\n",
    "    \n",
    "    for num_estimators in range(min_estimators, n_estimators + 1):\n",
    "        model.set_params(n_estimators=num_estimators)\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        score = roc_auc_score(y_test, model.predict_proba(x_test)[:, 1])\n",
    "        trial.report(score, num_estimators)\n",
    "    \n",
    "        if trial.should_prune():\n",
    "            raise TrialPruned()\n",
    "\n",
    "    kfold = KFold(shuffle=True, random_state=seed)\n",
    "    roc_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    scores = cross_val_score(model, x, y, cv=kfold, scoring=roc_auc)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median(scores)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDBzuzKHG6yL",
    "outputId": "82eab09e-5979-4580-a1ee-e908a6c3d428"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 15:11:00,130] A new study created in memory with name: optimization\n",
      "[W 2024-12-08 15:11:00,514] Trial 0 failed with parameters: {'n_estimators': 807, 'max_depth': 7, 'max_features': 0.21296783552104626, 'bootstrap': False} because of the following error: ValueError(\"could not convert string to float: 'cash loans'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_187908/244823179.py\", line 52, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, x_train, np.array(y_train).ravel()), n_trials=5) #n_trials=100 is the original value\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_187908/1609094541.py\", line 12, in objective\n",
      "    model.fit(x_train, y_train)\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1012, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lemuelrobinson/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/pandas/core/generic.py\", line 2153, in __array__\n",
      "    arr = np.asarray(values, dtype=dtype)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: could not convert string to float: 'cash loans'\n",
      "[W 2024-12-08 15:11:00,516] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'cash loans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187908/244823179.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moptuna\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'optimization'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n_trials=100 is the original value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mRaises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    115\u001b[0m                         )\n\u001b[1;32m    116\u001b[0m                     )\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_optimize_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m# Please refer to the following PR for further details:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# https://github.com/optuna/optuna/pull/325.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_187908/244823179.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(trial)\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n_trials=100 is the original value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_187908/1609094541.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(trial, x, y, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmin_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum_estimators\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         raise ValueError(\n\u001b[1;32m   1298\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         )\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         )\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Credit_Capstone/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'cash loans'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def instantiate_numerical_pipeline(trial : Trial) -> Pipeline:\n",
    "  pipeline = Pipeline([\n",
    "    ('imputer', instantiate_numerical_simple_imputer(trial)),\n",
    "    ('scaler', instantiate_scaler(trial))\n",
    "  ])\n",
    "  return pipeline\n",
    "\n",
    "def instantiate_categorical_pipeline(trial : Trial) -> Pipeline:\n",
    "  pipeline = Pipeline([\n",
    "    ('imputer', instantiate_categorical_simple_imputer(trial)),\n",
    "    ('encoder', instantiate_woe_encoder(trial))#instantiate_encoder(trial))\n",
    "  ])\n",
    "  return pipeline\n",
    "\n",
    "def instantiate_processor(trial : Trial, numerical_columns : list[str], categorical_columns : list[str]) -> ColumnTransformer:\n",
    "\n",
    "  numerical_pipeline = instantiate_numerical_pipeline(trial)\n",
    "  categorical_pipeline = instantiate_categorical_pipeline(trial)\n",
    "\n",
    "  selected_numerical_columns = choose_columns(trial,numerical_columns)\n",
    "  selected_categorical_columns = choose_columns(trial,categorical_columns)\n",
    "\n",
    "  processor = ColumnTransformer([\n",
    "    ('numerical_pipeline', numerical_pipeline, selected_numerical_columns),\n",
    "    ('categorical_pipeline', categorical_pipeline, selected_categorical_columns)\n",
    "  ])\n",
    "\n",
    "  return processor\n",
    "\n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], categorical_columns : list[str]) -> Pipeline:\n",
    "\n",
    "  processor = instantiate_processor(\n",
    "    trial, numerical_columns, categorical_columns\n",
    "  )\n",
    "\n",
    "  learner = instantiate_learner(trial)\n",
    "\n",
    "  model = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "  ])\n",
    "\n",
    "  return model\n",
    "\n",
    "from optuna import create_study\n",
    "\n",
    "study = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "study.optimize(lambda trial: objective(trial, x_train, np.array(y_train).ravel()), n_trials=5) #n_trials=100 is the original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7e9EIeUG6yL"
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcwNjbHluwMG"
   },
   "outputs": [],
   "source": [
    "study = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "study.optimize(lambda trial: objective(classifier='random_forest',trial=trial, X=x_train, y=np.array(y_train).ravel()), n_trials=1) #n_trials=100 is the original value\n",
    "\n",
    "best_trial: FrozenTrial = study.best_trial\n",
    "model: Pipeline = instantiate_model('random_forest',trial=best_trial, numerical_columns=numerical_columns, categorical_columns=categorical_columns)\n",
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)\n",
    "calculate_model_statistics(y_true=y_test, y_predict=predictions)\n",
    "\n",
    "#study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "\n",
    "from optuna import create_study\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "study = create_study(\n",
    "  direction=\"maximize\",\n",
    "  pruner=SuccessiveHalvingPruner(reduction_factor=2),\n",
    "  sampler=RandomSampler(seed=42) \n",
    ")\n",
    "study.optimize(lambda trial: objective(trial, x, y), n_trials=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gZV-cGpuwMG"
   },
   "outputs": [],
   "source": [
    "def iterative_bayesian_search(classifier, x_train, y_train, parameter_grid):\n",
    "    final_parameters = dict()\n",
    "    # define iteration dictionary\n",
    "\n",
    "    for key, value in parameter_grid.items():\n",
    "\n",
    "        #final_parameters[key]=value\n",
    "        iteration_grid = {key: value}\n",
    "        iteration_grid = {**final_parameters, **iteration_grid}\n",
    "\n",
    "        # do bayesian search\n",
    "        model_parameters = skopt_bayesian_search(\n",
    "            classifier, x_train, y_train, iteration_grid\n",
    "        )\n",
    "\n",
    "        # isolate iteration_grid parameter\n",
    "        final_parameters[key] = model_parameters[key]\n",
    "\n",
    "    return final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAb4tHVSuwMH"
   },
   "outputs": [],
   "source": [
    "def restrict_x_columns(x_train,x_test, columns):\n",
    "    x_train=x_train[:,columns]\n",
    "    x_test=x_test[:,columns]\n",
    "    return x_train,x_test\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hi5NJpxuwMH"
   },
   "source": [
    "Let's first implement bayesian optimization on a random forest model to see how well the data performs there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d4dw4rEuwMH"
   },
   "outputs": [],
   "source": [
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "model = TPOTClassifier(\n",
    "    generations=3,\n",
    "    population_size=50,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    verbosity=2,\n",
    "    random_state=15,\n",
    "    n_jobs=-1,\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best_pipeline = model.fitted_pipeline_\n",
    "tpot_classifier = clone(best_pipeline)\n",
    "tpot_classifier_params = tpot_classifier.steps[-1][1].get_params()\n",
    "tpot_classifier_name = str(type(best_pipeline.steps[-1][1])).split(\".\")[-1][:-2]\n",
    "\n",
    "# Fit the new classifier on the training data\n",
    "tpot_classifier.fit(training_x, training_y)\n",
    "predictions = tpot_classifier.predict(validation_x)\n",
    "tpot_accuracy = tpot_classifier.score(validation_x, validation_y)\n",
    "print(f\"\\n{tpot_classifier_name} accuracy is {tpot_accuracy:.3f}\")\n",
    "\n",
    "model_stats_df = calculate_model_statistics(\n",
    "    y_true=validation_y, y_predict=predictions, title=tpot_classifier_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bRnZ1fJuwMH"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": [\"gbdt\"],\n",
    "    \"num_leaves\": int_range(2, 15),\n",
    "    \"max_depth\": int_range(1, 15),\n",
    "    \"n_estimators\": np.linspace(50, 150, 10, dtype=int),#[50],\n",
    "    \"n_estimators\": np.linspace(50, 300, 10, dtype=int),\n",
    "    \"reg_alpha\": np.linspace(0, 1, 10),\n",
    "    \"reg_lambda\": np.linspace(0, 1, 10),\n",
    "    \"subsample\": np.linspace(0.1, 1, 20),\n",
    "}\n",
    "\n",
    "n_iter = 200\n",
    "classifier = LGBMClassifier(verbose=-1)\n",
    "metric = \"precision\"\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    classifier, param_distributions=params, n_iter=n_iter, scoring=metric\n",
    ")\n",
    "random_search.fit(x_train, y_train)\n",
    "#print(random_search.best_score_, random_search.best_params_)\n",
    "lgbm_params=random_search.best_params_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = random_search.predict(x_test)\n",
    "\n",
    "lgbm_metric: float = random_search.score(x_test, y_test)\n",
    "print(f\"LGBM classifier metric is {lgbm_metric:.3f}\")\n",
    "calculate_model_statistics(y_true=y_test, y_predict=predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lgbm_classifier: LGBMClassifier = LGBMClassifier(**lgbm_params).fit(\n",
    "    x_train, y_train\n",
    ")\n",
    "#predictions = lgbm_classifier.predict(x_test)\n",
    "\n",
    "#lgbm_accuracy: float = lgbm_classifier.score(x_test, y_test)\n",
    "#print(f\"LGBM classifier accuracy is {lgbm_accuracy:.3f}\")\n",
    "calculate_model_statistics(y_true=y_test, y_predict=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvIeAj1guwMI"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "# Declare xgboost search space for Hyperopt\n",
    "xgboost_space = {\n",
    "    \"max_depth\": hp.choice(\"x_max_depth\", [2, 3, 4, 5, 6]),\n",
    "    \"min_child_weight\": hp.choice(\n",
    "        \"x_min_child_weight\", np.round(np.arange(0.0, 0.2, 0.01), 5)\n",
    "    ),\n",
    "    \"learning_rate\": hp.choice(\n",
    "        \"x_learning_rate\", np.round(np.arange(0.005, 0.3, 0.01), 5)\n",
    "    ),\n",
    "    \"subsample\": hp.choice(\"x_subsample\", np.round(np.arange(0.1, 1.0, 0.05), 5)),\n",
    "    \"colsample_bylevel\": hp.choice(\n",
    "        \"x_colsample_bylevel\", np.round(np.arange(0.1, 1.0, 0.05), 5)\n",
    "    ),\n",
    "    \"colsample_bytree\": hp.choice(\n",
    "        \"x_colsample_bytree\", np.round(np.arange(0.1, 1.0, 0.05), 5)\n",
    "    ),\n",
    "    \"n_estimators\": hp.choice(\"x_n_estimators\", np.arange(25, 100, 5)),\n",
    "}\n",
    "\n",
    "best_score = 1.0\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "\n",
    "    global best_score\n",
    "    model = XGBClassifier(**space, n_jobs=-1)\n",
    "    kfold = KFold(n_splits=3, random_state=0, shuffle=True)\n",
    "    score = -cross_val_score(\n",
    "        model, x_train, y_train, cv=kfold, scoring=\"neg_log_loss\", verbose=False\n",
    "    ).mean()\n",
    "\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xgb_best_params = fmin(\n",
    "    objective, space=xgboost_space, algo=tpe.suggest, max_evals=200, trials=Trials()\n",
    ")\n",
    "\n",
    "print(\"Hyperopt search took %.2f seconds for 200 candidates\" % ((time.time() - start)))\n",
    "print(\"Best score: %.2f \" % (-best_score))\n",
    "print(\"Best space: \", xgb_best_params)\n",
    "xgb = XGBClassifier(**xgb_best_params)\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "predictions = xgb.predict(x_test)\n",
    "\n",
    "xgb_metric: float = random_search.score(x_test, y_test)\n",
    "print(f\"XGB classifier metric is {xgb_metric:.3f}\")\n",
    "calculate_model_statistics(y_true=y_test, y_predict=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPqAmTHLuwMI"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": np.linspace(35, 150, 50, dtype=int),\n",
    "    \"learning_rate\": np.linspace(0.01, 0.3, 12),\n",
    "}\n",
    "\n",
    "adaboost_params = skopt_bayesian_search(\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\"), x_train, y_train, params\n",
    ")\n",
    "adaboost_classifier: AdaBoostClassifier = AdaBoostClassifier(\n",
    "    algorithm=\"SAMME\", **adaboost_params\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "predictions = adaboost_classifier.predict(x_test)\n",
    "adaboost_accuracy: float = adaboost_classifier.score(x_test, y_test)\n",
    "print(f\"AdaBoost classifier accuracy is {adaboost_accuracy:.3f}\")\n",
    "model_stats_df['AdaboostClassifier'] = calculate_model_statistics(y_true=y_test, y_predict=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8m1PpUU5uwMI"
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yecM8wo2uwMJ"
   },
   "source": [
    "### Null value tolerant machine learning models\n",
    "Several supervised learning classification models can handle null or missing values to varying degrees. Here are some of the main classification models that are relatively tolerant of null values:\n",
    "Decision Trees and Random Forests\n",
    "Decision trees and random forest models are generally quite tolerant of missing values:\n",
    "During training, these models can work around missing values by using surrogate splits.\n",
    "For prediction, there are strategies like sending samples with missing values down both branches and averaging the results.\n",
    "Random forests in particular tend to be robust to missing data, as the ensemble nature helps mitigate issues with individual trees1.\n",
    "Naive Bayes\n",
    "Naive Bayes classifiers can handle missing values naturally:\n",
    "For categorical features, missing values can be treated as a separate category.\n",
    "For numerical features, missing values can be ignored when calculating means and variances.\n",
    "This makes Naive Bayes models quite tolerant of null values without requiring imputation2.\n",
    "K-Nearest Neighbors (KNN)\n",
    "KNN can work with missing data by using:\n",
    "Partial distance calculations that ignore missing features\n",
    "Imputation of missing values based on nearest neighbors\n",
    "While not inherently null-tolerant, KNN can be adapted to handle missing data reasonably well3.\n",
    "Support Vector Machines (SVM)\n",
    "SVMs don't directly handle missing values, but can be made more robust by:\n",
    "Using kernels that can handle missing data\n",
    "Imputing missing values before training\n",
    "With appropriate preprocessing, SVMs can work effectively even with some missing data1.\n",
    "Gradient Boosting Models\n",
    "Gradient boosting models like XGBoost and LightGBM have built-in methods for handling missing values:\n",
    "They can learn the best direction to take for missing values at each split.\n",
    "This allows them to handle missing data both during training and prediction without explicit imputation1.\n",
    "While these models can work with missing data, it's generally recommended to investigate the reason for missing values and consider imputation strategies where appropriate. The performance impact of missing data can vary depending on the specific dataset and problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtAZJZQsurF0"
   },
   "outputs": [],
   "source": [
    "px.violin(bureau, x=\"credit_day_overdue\").show()\n",
    "bureau.to_pandas().value_counts(\"credit_day_overdue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrPJYayqurF0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfdxdzKEurF0"
   },
   "outputs": [],
   "source": [
    "# pos_cash_balance: DataFrame = create_formatted_df(\"POS_CASH_balance.csv\")\n",
    "corr = pos_cash_balance.select(cs.by_dtype(pl.NUMERIC_DTYPES)).to_pandas().corr()\n",
    "features = pos_cash_balance.select(cs.by_dtype(pl.NUMERIC_DTYPES)).to_pandas().columns\n",
    "clear(pos_cash_balance)\n",
    "\n",
    "mask = np.tril(np.ones_like(corr, dtype=bool))\n",
    "masked_corr = corr.where(mask)\n",
    "masked_corr.columns = features\n",
    "masked_corr.index = features\n",
    "\n",
    "styled_corr = masked_corr.style.background_gradient(cmap=\"GnBu\").format(\"{:.3f}\")\n",
    "styled_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8ch3soxurF0"
   },
   "outputs": [],
   "source": [
    "# Print all columns in training set\n",
    "train_desc = description.filter(pl.col(\"table\") == \"application_{train|test}.csv\")[\n",
    "    [\"row\", \"description\"]\n",
    "].to_pandas()\n",
    "for row in range(len(train_desc)):\n",
    "    print(train_desc.iloc[row, 0], \": \", train_desc.iloc[row, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWPMlx44uwMK"
   },
   "outputs": [],
   "source": [
    "# for all variables in training set\n",
    "# Calculate correlation of target with variable x.\n",
    "# if absolute value of corr is >.3 and <.7, add to some correlation bucket\n",
    "# elif absolute value is >.7, add to strong correlation bucket\n",
    "# else put variable in no correlation bucket\n",
    "\n",
    "\n",
    "def group_correlations(df, feature_of_interest):\n",
    "    no_corr = dict()\n",
    "    weak_corr = dict()\n",
    "    strong_corr = dict()\n",
    "\n",
    "    for feature in df.select(cs.numeric()).columns:\n",
    "        if feature == feature_of_interest:\n",
    "            continue\n",
    "\n",
    "        # pg.partial_corr(data=application_train.to_pandas(), x='target', y='amt_goods_price', covar='target')#['r'].values[0]\n",
    "\n",
    "        corr_df = df[[feature_of_interest, feature]]\n",
    "        # corr=pg.partial_corr(data=application_train.to_pandas(), x=feature_of_interest, y=feature, covar='target')#['r'].values[0]\n",
    "        corr = corr_df.to_pandas().corr().iloc[0, 1]\n",
    "        if np.abs(corr) >= 0.7:\n",
    "            strong_corr[feature] = corr\n",
    "        elif np.abs(corr) <= 0.3:\n",
    "            no_corr[feature] = corr\n",
    "        else:\n",
    "            weak_corr[feature] = corr\n",
    "\n",
    "    index = [feature_of_interest]\n",
    "    strong_corr = pd.DataFrame(\n",
    "        data=strong_corr, index=index\n",
    "    )  # columns=strong_corr.keys(), )\n",
    "    weak_corr = pd.DataFrame(data=weak_corr, index=index)\n",
    "    no_corr = pd.DataFrame(data=no_corr, index=index)\n",
    "    return strong_corr, weak_corr, no_corr\n",
    "\n",
    "\n",
    "strong, weak, no = group_correlations(application_train, \"target\")\n",
    "\n",
    "no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu5MURZquwMK"
   },
   "outputs": [],
   "source": [
    "# partial correlation\n",
    "pg.partial_corr(\n",
    "    data=application_train.to_pandas(), x=\"target\", y=\"amt_goods_price\", covar=\"target\"\n",
    ")[\"r\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMxKlexQuwMK"
   },
   "source": [
    "#### NB: The important point is for BorutaPy, multicollinearity should be removed before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ltLgOfsuwMK"
   },
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Set x to only features that have no null values\n",
    "x = application_train[x_features_no_nulls].drop(\"target\")  # .to_pandas()\n",
    "y = pl.DataFrame(application_train[\"target\"])  # .to_pandas()\n",
    "\n",
    "# Conduct PCA to remove multicolinearity from training set\n",
    "pca = PCA(n_components=len(x.columns))  # , svd_solver='full')\n",
    "pca.fit_transform(x)\n",
    "\n",
    "\n",
    "x_features_no_nulls = list(\n",
    "    null_df.filter(pl.col(\"null_count\") == 0).select(\"features\").to_series()\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "boruta = BorutaPy(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    # n_estimators=54,  # \"auto\",\n",
    "    max_iter=100,\n",
    ")\n",
    "boruta.fit(np.array(x_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yO8wLGbwuwMK"
   },
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(x_train.columns, columns=[\"features\"])\n",
    "feature_df[\"rank\"] = boruta.ranking_\n",
    "feature_df[\"included_features\"] = boruta.support_\n",
    "# feature_df.with_columns(boruta.ranking_).alias(\"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZP1EBQ5vuwML"
   },
   "outputs": [],
   "source": [
    "# Full training set correlations\n",
    "\n",
    "# pos_cash_balance: DataFrame = create_formatted_df(\"POS_CASH_balance.csv\")\n",
    "corr = application_train.select(cs.by_dtype(pl.NUMERIC_DTYPES)).to_pandas().corr()\n",
    "features = application_train.select(cs.by_dtype(pl.NUMERIC_DTYPES)).to_pandas().columns\n",
    "# clear(pos_cash_balance)\n",
    "\n",
    "mask = np.tril(np.ones_like(corr, dtype=bool))\n",
    "masked_corr = corr.where(mask)\n",
    "masked_corr.columns = features\n",
    "masked_corr.index = features\n",
    "\n",
    "styled_corr = masked_corr.style.background_gradient(cmap=\"GnBu\").format(\"{:.3f}\")\n",
    "styled_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq9OKy72uwML"
   },
   "outputs": [],
   "source": [
    "# Setting numeric & categorical features for further analysis\n",
    "response = \"target\"\n",
    "# cat_feats = [c for c in x.select(cs.string())]\n",
    "# bin_feats = [c for c in x.columns if '_bin' in c]\n",
    "# cat_feats = cat_feats + bin_feats˛\n",
    "num_feats = [c for c in x.select(cs.numeric())]\n",
    "\n",
    "# x_train, x_test, y_train, y_test\n",
    "x_train = x_train.to_pandas()\n",
    "x_test = x_test.to_pandas()\n",
    "y_train = y_train.to_pandas()\n",
    "y_test = y_test.to_pandas()\n",
    "\n",
    "\n",
    "# x[num_feats] = x[num_feats].astype('float')\n",
    "# x[cat_feats] = x[cat_feats].astype('object')\n",
    "\n",
    "# x.replace(-1, np.nan, inplace=True)\n",
    "#!pip install autofeatselect\n",
    "from autofeatselect import CorrelationCalculator, FeatureSelector, AutoFeatureSelect\n",
    "\n",
    "# Create AutoFeatureSelect class\n",
    "feat_selector = AutoFeatureSelect(\n",
    "    modeling_type=\"classification\",\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    X_test=x_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=num_feats,\n",
    "    categorical_columns=[],  # cat_feats,\n",
    "    seed=24,\n",
    ")\n",
    "\n",
    "# Detect Correlated Features\n",
    "corr_features = feat_selector.calculate_correlated_features(\n",
    "    static_features=None, num_threshold=0.9, cat_threshold=0.9\n",
    ")\n",
    "# Drop Correlated Features\n",
    "feat_selector.drop_correlated_features()\n",
    "\n",
    "# Determine Selection Methods to Apply\n",
    "# Options: 'lgbm', 'xgb', 'rf','perimp', 'rfecv', 'boruta', 'lassocv'\n",
    "# Note: Hyperparameters of all methods can be changed\n",
    "selection_methods = [\"lgbm\", \"xgb\", \"rf\", \"perimp\", \"rfecv\", \"boruta\"]\n",
    "final_importance_df = feat_selector.apply_feature_selection(\n",
    "    selection_methods=selection_methods,\n",
    "    lgbm_hyperparams=None,\n",
    "    xgb_hyperparams=None,\n",
    "    rf_hyperparams=None,\n",
    "    lassocv_hyperparams=None,\n",
    "    perimp_hyperparams=None,\n",
    "    rfecv_hyperparams=None,\n",
    "    boruta_hyperparams=None,\n",
    ")\n",
    "\n",
    "# Print Results\n",
    "final_importance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY9ycwd1uwML"
   },
   "outputs": [],
   "source": [
    "from autofeatselect import CorrelationCalculator, FeatureSelector, AutoFeatureSelect\n",
    "\n",
    "# Static features will not be removed even if they are correlated with other features.\n",
    "static_features = [\"sk_id_curr\"]\n",
    "\n",
    "# Detect correlated features\n",
    "corr_df_num, num_remove_list = CorrelationCalculator.numeric_correlations(\n",
    "    application_train,\n",
    "    features=application_train.columns,\n",
    "    static_features=static_features,\n",
    "    threshold=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zko0QtI0uwML"
   },
   "source": [
    "#### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec7vqBX0uwMM"
   },
   "outputs": [],
   "source": [
    "x1=application_train.select(feature_set1)\n",
    "\n",
    "# scale data\n",
    "scaled_x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# x_features_no_nulls = list(null_df.filter(pl.col(\"null_count\") == 0).select(\"features\").to_series())\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    scaled_x, y, test_size=0.2, stratify=y\n",
    ")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "y_train=y_train.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jer_jW_FuwMM"
   },
   "outputs": [],
   "source": [
    "# Specify the different options for hyperparameters\n",
    "grid = {\n",
    "    \"C\": np.logspace(-3, 3, 5),\n",
    "    # \"penalty\": [\"l1\", \"l2\", None],\n",
    "    \"solver\": [\"saga\", \"newton-cholesky\", \"liblinear\", \"sag\", \"saga\", \"lbfgs\"],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    \"tol\": np.linspace(0, 0.5, 10),\n",
    "}\n",
    "\n",
    "regression = LogisticRegression(max_iter=1000)\n",
    "\n",
    "regression_params = skopt_bayesian_search(\n",
    "    regression, x_train, y_train, grid\n",
    ")  # ,np=True)\n",
    "\n",
    "# tuned_regression = LogisticRegression(**regression_params).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(regression_params)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
